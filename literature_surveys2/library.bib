@article{baker2016a,
    title = {{1,500 scientists lift the lid on reproducibility}},
    journal = {Nature News},
    author = {Baker, M},
    number = {7604},
    pages = {452},
    volume = {533}
}

@article{shannon-a,
    title = {{1950. “Programming a Computer for Playing Chess”}},
    journal = {Philosophical Magazine},
    author = {Shannon, C},
    number = {314},
    volume = {41}
}

@incollection{gu2017b,
    title = {{2016a. “Q-prop: Sample-efficient policy gradient with an off-policy critic”}},
    booktitle = {5th International Conference on Learning Representations},
    author = {Gu, S and Lillicrap, T and Ghahramani, Z and Turner, R E and Levine, S},
    edition = {arXiv prep},
    publisher = {ICLR}
}

@misc{gu-b,
    title = {{2017c. “Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning”}},
    author = {Gu, S and Lillicrap, T and Ghahramani, Z and Turner, R E and Sch{\"{o}}lkopf, B and Levine, S},
    edition = {arXiv prep}
}

@book{hacker,
    title = {{A Computer Model of Skill Acquisition}},
    year = {1975},
    author = {Sussman, G J},
    publisher = {New York: New American Elsevier}
}

@inproceedings{adorf,
    title = {{A Discrete Stochastic Neural Network Algorithm for Constraint Satisfaction Problems}},
    year = {1990},
    booktitle = {Proceedings of the International Joint Conference on Neural Networks},
    author = {Adorf, H M and Johnston, M D}
}

@misc{zhang-a,
    title = {{A Dissection of Overfitting and Generalization in Continuous Reinforcement Learning}},
    author = {Zhang A., N Ballas and 2018a, J Pineau.},
    edition = {arXiv prep}
}

@misc{bellemare2017a,
    title = {{A distributional perspective on reinforcement learning}},
    author = {Bellemare, M G and Dabney, W and Munos, R},
    edition = {arXiv prep}
}

@techreport{Bellemare2017,
    title = {{A Distributional Perspective on Reinforcement Learning}},
    year = {2017},
    author = {Bellemare, Marc G and Dabney, Will and Munos, Rémi},
    url = {https://arxiv.org/pdf/1707.06887.pdf http://proceedings.mlr.press/v70/bellemare17a/bellemare17a.pdf},
    arxivId = {1707.06887v1}
}

@misc{machado-a,
    title = {{A Laplacian Framework for Option Discovery in Reinforcement Learning}},
    author = {Machado M. C., M G Bellemare and 2017a, M Bowling.},
    edition = {arXiv prep}
}

@article{giusti2016a,
    title = {{A machine learning approach to visual perception of forest trails for mobile robots}},
    journal = {IEEE Robotics and Automation Letters},
    author = {Giusti, A and Guzzi, J and Cire{\c{s}}an, D C and He, F.-L. and Rodriguez, J P and Fontana, F and Faessler, M and Forster, C and Schmidhuber, J and Caro, G.Di},
    number = {2},
    pages = {661–667},
    volume = {1}
}

@article{bellman-a,
    title = {{A Markovian decision process}},
    journal = {Journal of Mathematics and Mechanics},
    author = {Bellman, R 1957a},
    pages = {679–684}
}

@article{Phillips2004,
    title = {{A maximum entropy approach to species distribution modeling}},
    year = {2004},
    journal = {Twentyfirst international conference on Machine learning ICML 04},
    author = {Phillips, Steven J and Dud{\'{i}}k, M and Schapire, R E},
    pages = {83},
    volume = {69},
    url = {http://portal.acm.org/citation.cfm?doid=1015330.1015412},
    isbn = {1581138285},
    doi = {10.1145/1015330.1015412},
    issn = {00147672},
    pmid = {6379}
}

@incollection{kakade2001a,
    title = {{A Natural Policy Gradient}},
    booktitle = {Advances in Neural},
    author = {Kakade, S}
}

@article{schultz1997a,
    title = {{A neural substrate of prediction and reward}},
    journal = {Science},
    author = {Schultz, W and Dayan, P and Montague, P R},
    number = {5306},
    pages = {1593–1599},
    volume = {275}
}

@misc{santoro2017a,
    title = {{A simple neural network module for relational reasoning}},
    author = {Santoro, A and Raposo, D and Barrett, D G and Malinowski, M and Pascanu, R and Battaglia, P and Lillicrap, T},
    edition = {arXiv prep}
}

@incollection{browne2012a,
    title = {{A survey of monte carlo tree search methods}},
    booktitle = {IEEE Transactions on Computational Intelligence and AI in games},
    author = {Browne, C B and Powley, E and Whitehouse, D and Lucas, S M and Cowling, P I and Rohlfshagen, P and Tavener, S and Perez, D and Samothrakis, S and Colton, S},
    number = {1},
    pages = {1–43},
    volume = {4}
}

@inproceedings{simmons-aaai88,
    title = {{A Theory of Debugging Plans and Interpretations}},
    year = {1988},
    booktitle = {Proceedings of AAAI-88},
    author = {Simmons, R G}
}

@incollection{rescorla1972a,
    title = {{A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement}},
    booktitle = {Classical conditioning II: Current research and theory. 2},
    author = {Rescorla, R A and Wagner, A R},
    pages = {64–99}
}

@misc{duan-a,
    title = {{Abbeel. 2016b. “RL2: Fast Reinforcement Learning via Slow Reinforcement Learning”}},
    author = {Duan, Y and Schulman, J and Chen, X and Bartlett, P L and Sutskever, I and {P.}},
    edition = {arXiv prep}
}

@inproceedings{jiang-a,
    title = {{Abstraction selection in model-based reinforcement learning}},
    booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
    author = {Jiang N., A Kulesza and 2015a, S Singh.},
    pages = {179–188},
    volume = {15}
}

@incollection{oh2015a,
    title = {{Actionconditional video prediction using deep networks in atari games}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Oh, J and Guo, X and Lee, H and Lewis, R L and Singh, S},
    pages = {2863–2871}
}

@misc{parisotto2015a,
    title = {{Actor-mimic: Deep multitask and transfer reinforcement learning}},
    author = {Parisotto, E and Ba, J L and Salakhutdinov, R},
    edition = {arXiv prep}
}

@misc{tzeng2015a,
    title = {{Adapting deep visuomotor representations with weak pairwise constraints}},
    author = {Tzeng, E and Devin, C and Hoffman, J and Finn, C and Abbeel, P and Levine, S and Saenko, K and Darrell, T},
    edition = {arXiv prep}
}

@incollection{mankowitz2016a,
    title = {{Adaptive Skills Adaptive Partitions (ASAP)}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Mankowitz, D J and Mann, T A and Mannor, S},
    pages = {1588–1596}
}

@article{Huang2017,
    title = {{Adversarial Attacks on Neural Network Policies}},
    year = {2017},
    author = {Huang, Sandy and Papernot, Nicolas and Goodfellow, Ian and Duan, Yan and Abbeel, Pieter},
    month = {2},
    url = {http://arxiv.org/abs/1702.02284},
    arxivId = {1702.02284}
}

@book{brassard,
    title = {{Algorithmics - Theory and Practice}},
    year = {1988},
    author = {Brassard, G and Bratley, P},
    publisher = {Englewood Cliffs, NJ: Prentice Hall}
}

@misc{bahdanau2016a,
    title = {{An actor-critic algorithm for sequence prediction}},
    author = {Bahdanau, D and Brakel, P and Xu, K and Goyal, A and Lowe, R and Pineau, J and Courville, A and Bengio, Y},
    edition = {arXiv prep}
}

@misc{rowland2018a,
    title = {{An Analysis of Categorical Distributional Reinforcement Learning}},
    author = {Rowland, M and Bellemare, M G and Dabney, W and Munos, R and Teh, Y W},
    edition = {arXiv prep}
}

@article{Strehl2008,
    title = {{An analysis of model-based Interval Estimation for Markov Decision Processes}},
    year = {2008},
    journal = {Journal of Computer and System Sciences},
    author = {Strehl, Alexander L and Littman, Michael L},
    pages = {1309--1331},
    volume = {74},
    url = {www.elsevier.com/locate/jcss},
    doi = {10.1016/j.jcss.2007.08.009},
    keywords = {Learning theory, Markov Decision Processes, Reinforcement learning}
}

@article{tsitsiklis1997a,
    title = {{An analysis of temporaldifference learning with function approximation}},
    journal = {Automatic Control, IEEE Transactions on},
    author = {Tsitsiklis, J N and Roy, B.Van},
    number = {5},
    pages = {674–690},
    volume = {42}
}

@article{Francois-Lavet2018,
    title = {{An Introduction to Deep Reinforcement Learning}},
    year = {2018},
    author = {Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle},
    url = {https://arxiv.org/pdf/1811.12560.pdf},
    doi = {10.1561/2200000071},
    arxivId = {1811.12560v2}
}

@book{anderson1958a,
    title = {{An introduction to multivariate statistical analysis}},
    author = {Anderson, T W and Anderson, T W and Anderson, T W and Anderson, T W and Math{\'{e}}maticien, E.-U.},
    volume = {2},
    publisher = {Wiley},
    address = {New York}
}

@misc{ruder2017a,
    title = {{An overview of multi-task learning in deep neural networks}},
    author = {Ruder, S},
    edition = {arXiv prep}
}

@incollection{wender2012a,
    title = {{Applying reinforcement learning to small scale combat in the real-time strategy game StarCraft: Broodwar}},
    booktitle = {Computational Intelligence and Games (CIG), 2012 IEEE Conference on. IEEE},
    author = {Wender, S and Watson, I},
    pages = {402–408}
}

@misc{neu2012a,
    title = {{Apprenticeship learning using inverse reinforcement learning and gradient methods}},
    author = {Neu, G and Szepesv{\'{a}}ri, C},
    edition = {arXiv prep}
}

@inproceedings{abbeel2004a,
    title = {{Apprenticeship learning via inverse reinforcement learning}},
    booktitle = {Proceedings of the twenty-first international conference on Machine learning. ACM},
    author = {Abbeel, P and Ng, A Y}
}

@incollection{cou2017a,
    title = {{Approximate Bayes Optimal Policy Search using Neural Networks}},
    booktitle = {9th International Conference on Agents and Artificial Intelligence (ICAART},
    author = {{Cou{\"{e}}toux}}
}

@inproceedings{dinculescu2010a,
    title = {{Approximate predictive representations of partially observable systems}},
    booktitle = {Proceedings of the 27th International Conference on Machine Learning},
    author = {Dinculescu, M and Precup, D},
    pages = {895–902},
    volume = {10}
}

@book{gordon1999a,
    title = {{Approximate solutions to Markov decision processes}},
    author = {Gordon, G J},
    publisher = {Robotics Institute: 228}
}

@incollection{bennett2013a,
    title = {{Artificial intelligence framework for simulating clinical decision-making: A Markov decision process approach}},
    booktitle = {Artificial intelligence in medicine},
    author = {Bennett, C C and Hauser, K},
    number = {1},
    pages = {9–19},
    volume = {57}
}

@misc{unknown-a,
    title = {{Asymmetric Actor Critic for Image-Based Robot Learning”}},
    edition = {arXiv prep}
}

@techreport{Mnih2016b,
    title = {{Asynchronous Methods for Deep Reinforcement Learning}},
    year = {2016},
    author = {Mnih, Volodymyr and Puigdom{\`{e}}nech Badia, Adrià and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P and Silver, David and Kavukcuoglu, Koray},
    url = {http://proceedings.mlr.press/v48/mniha16.pdf}
}

@misc{vaswani2017a,
    title = {{Attention Is All You Need}},
    author = {Vaswani, A and Shazeer, N and Parmar, N and Uszkoreit, J and Jones, L and Gomez, A N and Kaiser, L and Polosukhin, I},
    edition = {arXiv prep}
}

@incollection{kroon2009a,
    title = {{Automatic feature selection for model-based reinforcement learning in factored MDPs}},
    booktitle = {Machine Learning and Applications, 2009. ICMLA’09. International Conference on. IEEE},
    author = {Kroon, M and Whiteson, S},
    pages = {324–330}
}

@incollection{florensa2018a,
    title = {{Automatic goal generation for reinforcement learning agents}},
    booktitle = {International Conference on Machine Learning},
    author = {Florensa, C and Held, D and Geng, X and Abbeel, P},
    pages = {1514–1523}
}

@article{fonteneau2013a,
    title = {{Batch mode reinforcement learning based on the synthesis of artificial trajectories}},
    journal = {Annals of operations research},
    author = {Fonteneau, R and Murphy, S A and Wehenkel, L and Ernst, D},
    number = {1},
    pages = {383–416},
    volume = {208}
}

@misc{ioffe2015a,
    title = {{Batch normalization: Accelerating deep network training by reducing internal covariate shift}},
    author = {Ioffe, S and Szegedy, C},
    edition = {arXiv prep}
}

@inproceedings{dearden2011a,
    title = {{Bayesian Q-learning}},
    booktitle = {Proceedings of the 28th International Conference on machine learning},
    author = {Dearden R., N Friedman and 1998, S Russell.},
    pages = {465–472},
    volume = {11}
}

@incollection{ghavamzadeh2015a,
    title = {{Bayesian reinforcement learning: A survey}},
    booktitle = {Foundations and Trends{\textregistered} in Machine Learning},
    author = {Ghavamzadeh, M and Mannor, S and Pineau, J and Tamar, A},
    number = {5-6},
    pages = {359–483},
    volume = {8}
}

@misc{kaplan2017a,
    title = {{Beating Atari with Natural Language Guided Reinforcement Learning}},
    author = {Kaplan, R and Sauer, C and Sosa, A},
    edition = {arXiv prep}
}

@incollection{duan2016a,
    title = {{Benchmarking deep reinforcement learning for continuous control}},
    booktitle = {International Conference on Machine Learning},
    author = {Duan, Y and Chen, X and Houthooft, R and Schulman, J and Abbeel, P},
    pages = {1329–1338}
}

@misc{zhang-b,
    title = {{Bengio. 2018c. “A Study on Overfitting in Deep Reinforcement Learning”}},
    author = {Zhang, C and Vinyals, O and Munos, R and {S.}},
    edition = {arXiv prep}
}

@misc{Devlin2018,
    title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
    year = {2018},
    author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina and Google, Kristina Toutanova and Language, A I and Toutanova, Kristina},
    month = {10},
    url = {http://arxiv.org/abs/1810.04805 https://github.com/tensorflow/tensor2tensor}
}

@article{sutton1999a,
    title = {{Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning}},
    journal = {Artificial},
    author = {Sutton, R S and Precup, D and Singh, S},
    number = {1-2},
    pages = {181–211},
    volume = {112}
}

@incollection{thomas2014a,
    title = {{Bias in natural actor-critic algorithms}},
    booktitle = {International Conference on Machine Learning},
    author = {Thomas, P},
    pages = {441–448}
}

@misc{wang-a,
    title = {{Botvinick. 2016a. “Learning to reinforcement learn”}},
    author = {Wang, J X and Kurth-Nelson, Z and Tirumala, D and Soyer, H and Leibo, J Z and Munos, R and Blundell, C and Kumaran, D and {M.}},
    edition = {arXiv prep}
}

@incollection{coumans2016a,
    title = {{Bullet}},
    author = {Coumans, E and Bai, Y},
    edition = {Barto.2012},
    url = {http://pybullet.org/.}
}

@misc{sadeghi2016a,
    title = {{CAD2RL: Real single-image flight without a single real image}},
    author = {Sadeghi, F and Levine, S},
    edition = {arXiv prep}
}

@article{piketty2013a,
    title = {{Capital in the Twenty-First Century}},
    journal = {In: IJCAI},
    author = {Piketty, T},
    pages = {1025–1032},
    volume = {3}
}

@article{salge2014a,
    title = {{Changing the environment based on empowerment as intrinsic motivation}},
    journal = {Entropy},
    author = {Salge, C and Glackin, C and Polani, D},
    number = {5},
    pages = {2789–2819},
    volume = {16}
}

@inproceedings{bouckaert2003a,
    title = {{Choosing between two learning algorithms based on calibrated tests}},
    booktitle = {Proceedings of the 20th International Conference on Machine Learning},
    author = {Bouckaert, R R},
    pages = {51–58},
    volume = {3}
}

@article{liaw2002a,
    title = {{Classification and regression by randomForest}},
    journal = {R news},
    author = {Liaw, A and Wiener, M},
    number = {3},
    pages = {18–22},
    volume = {2}
}

@misc{chebotar2018a,
    title = {{Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience}},
    author = {Chebotar, Y and Handa, A and Makoviychuk, V and Macklin, M and Issac, J and Ratliff, N and Fox, D},
    edition = {arXiv prep}
}

@misc{fran2018a,
    title = {{Combined Reinforcement Learning via Abstract Representations}},
    author = {Fran{\c{c}}ois-Lavet, V and Bengio, Y and Precup, D and Pineau, J},
    edition = {arXiv prep}
}

@misc{amodei2016a,
    title = {{Concrete problems in AI safety}},
    author = {Amodei, D and Olah, C and Steinhardt, J and Christiano, P and Schulman, J and Man{\'{e}}, D},
    edition = {arXiv prep}
}

@book{pavlov1927a,
    title = {{Conditioned reflexes}},
    author = {Pavlov, I P},
    publisher = {Oxford University Press}
}

@misc{lillicrap2015a,
    title = {{Continuous control with deep reinforcement learning}},
    author = {Lillicrap, T P and Hunt, J J and Pritzel, A and Heess, N and Erez, T and Tassa, Y and Silver, D and Wierstra, D},
    edition = {arXiv prep}
}

@article{Lillicrap2015,
    title = {{Continuous control with deep reinforcement learning: Deep Deterministic Policy Gradients (DDPG)}},
    year = {2015},
    journal = {ICLR},
    author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
    arxivId = {1509.02971}
}

@misc{gu2016a,
    title = {{Continuous Deep Q-Learning with Model-based Acceleration}},
    author = {Gu, S and Lillicrap, T and Sutskever, I and Levine, S},
    edition = {arXiv prep}
}

@misc{oh2016a,
    title = {{Control of Memory, Active Perception, and Action in Minecraft}},
    author = {Oh, J and Chockalingam, V and Singh, S and Lee, H},
    edition = {arXiv prep}
}

@article{singh2000a,
    title = {{Convergence results for single-step on-policy reinforcement-learning algorithms}},
    journal = {Machine learning},
    author = {Singh, S and Jaakkola, T and Littman, M L and Szepesv{\'{a}}ri, C},
    number = {3},
    pages = {287–308},
    volume = {38}
}

@misc{ostrovski2017a,
    title = {{Count-based exploration with neural density models}},
    author = {Ostrovski, G and Bellemare, M G and v. d. Oord, A and Munos, R},
    edition = {arXiv prep}
}

@misc{foerster2017a,
    title = {{Counterfactual Multi-Agent Policy Gradients}},
    author = {Foerster, J and Farquhar, G and Afouras, T and Nardelli, N and Whiteson, S},
    edition = {arXiv prep}
}

@incollection{pathak2017a,
    title = {{Curiositydriven exploration by self-supervised prediction}},
    booktitle = {International Conference on Machine Learning (ICML)},
    author = {Pathak, D and Agrawal, P and Efros, A A and Darrell, T},
    volume = {Vol.}
}

@inproceedings{bengio2009a,
    title = {{Curriculum learning}},
    booktitle = {Proceedings of the 26th annual international conference on machine learning. ACM},
    author = {Bengio, Y and Louradour, J and Collobert, R and Weston, J},
    pages = {41–48}
}

@misc{higgins2017a,
    title = {{Darla: Improving zero-shot transfer in reinforcement learning}},
    author = {Higgins, I and Pal, A and Rusu, A A and Matthey, L and Burgess, C P and Pritzel, A and Botvinick, M and Blundell, C and Lerchner, A},
    edition = {arXiv prep}
}

@techreport{Popov,
    title = {{Data-efficient Deep Reinforcement Learning for Dexterous Manipulation}},
    author = {Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Deepmind, Martin Riedmiller},
    url = {https://pdfs.semanticscholar.org/e701/9d9786af58f56c5de7e7daa2ce9050ba60f0.pdf}
}

@incollection{thomas2016a,
    title = {{Data-efficient off-policy policy evaluation for reinforcement learning}},
    booktitle = {International Conference on Machine Learning},
    author = {Thomas, P S and Brunskill, E}
}

@article{dayan2008a,
    title = {{Decision theory, reinforcement learning, and the brain}},
    journal = {Cognitive, Affective, {\&} Behavioral Neuroscience},
    author = {Dayan, P and Daw, N D},
    number = {4},
    pages = {429–453},
    volume = {8}
}

@misc{zhang2018a,
    title = {{Decoupling Dynamics and Reward for Transfer Learning}},
    author = {Zhang, A and Satija, H and Pineau, J},
    edition = {arXiv prep}
}

@inproceedings{Lange2010,
    title = {{Deep auto-encoder neural networks in reinforcement learning}},
    year = {2010},
    booktitle = {Proceedings of the International Joint Conference on Neural Networks},
    author = {Lange, Sascha and Riedmiller, Martin},
    isbn = {9781424469178},
    doi = {10.1109/IJCNN.2010.5596468},
    issn = {1098-7576},
    pmid = {25719670},
    arxivId = {1507.04296}
}

@article{campbell2002a,
    title = {{Deep blue}},
    journal = {Artificial},
    author = {Campbell, M and Hoane, A J and Hsu, F.-h},
    number = {1-2},
    pages = {57–83},
    volume = {134}
}

@article{Peters2018,
    title = {{Deep contextualized word representations}},
    year = {2018},
    author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
    month = {2},
    url = {http://arxiv.org/abs/1802.05365},
    arxivId = {1802.05365}
}

@article{deng2017a,
    title = {{Deep direct reinforcement learning for financial signal representation and trading}},
    journal = {IEEE transactions on neural networks and learning systems},
    author = {Deng, Y and Bao, F and Kong, Y and Ren, Z and Dai, Q},
    number = {3},
    pages = {653–664},
    volume = {28}
}

@misc{osband2016a,
    title = {{Deep Exploration via Bootstrapped DQN}},
    author = {Osband, I and Blundell, C and Pritzel, A and Roy, B.Van},
    edition = {arXiv prep}
}

@book{goodfellow2016a,
    title = {{Deep learning}},
    author = {Goodfellow, I and Bengio, Y and Courville, A},
    publisher = {MIT Press}
}

@article{lecun2015a,
    title = {{Deep learning}},
    journal = {Nature},
    author = {LeCun, Y and Bengio, Y and Hinton, G},
    number = {7553},
    pages = {436–444},
    volume = {521}
}

@article{schmidhuber2015a,
    title = {{Deep learning in neural networks: An overview}},
    journal = {Neural Networks},
    author = {Schmidhuber, J},
    pages = {85–117},
    volume = {61}
}

@misc{mathieu2015a,
    title = {{Deep multi-scale video prediction beyond mean square error}},
    author = {Mathieu, M and Couprie, C and LeCun, Y},
    edition = {arXiv prep}
}

@misc{hausknecht2015a,
    title = {{Deep recurrent Q-learning for partially observable MDPs}},
    author = {Hausknecht, M and Stone, P},
    edition = {arXiv prep}
}

@incollection{gu2017a,
    title = {{Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates}},
    booktitle = {Robotics and Automation (ICRA), 2017 IEEE International Conference on. IEEE},
    author = {Gu, S and Holly, E and Lillicrap, T and Levine, S},
    pages = {3389–3396}
}

@misc{christiano2017a,
    title = {{Deep reinforcement learning from human preferences}},
    author = {Christiano, P and Leike, J and Brown, T B and Martic, M and Legg, S and Amodei, D},
    edition = {arXiv prep}
}

@incollection{fran2016b,
    title = {{Deep Reinforcement Learning Solutions for Energy Microgrids Management}},
    booktitle = {European Workshop on Reinforcement Learning},
    author = {Fran{\c{c}}ois-Lavet, V and Taralla, D and Ernst, D and Fonteneau, R}
}

@misc{henderson2017b,
    title = {{Deep Reinforcement Learning that Matters}},
    author = {Henderson, P and Islam, R and Bachman, P and Pineau, J and Precup, D and Meger, D},
    edition = {arXiv prep}
}

@techreport{Henderson,
    title = {{Deep Reinforcement Learning that Matters}},
    author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
    url = {www.aaai.org},
    arxivId = {1709.06560v2},
    keywords = {Machine Learning Methods Track}
}

@inproceedings{he2016a,
    title = {{Deep residual learning for image recognition}},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    author = {He, K and Zhang, X and Ren, S and Sun, J},
    pages = {770–778}
}

@misc{warnell2017a,
    title = {{Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces}},
    author = {Warnell, G and Waytowich, N and Lawhern, V and Stone, P},
    edition = {arXiv prep}
}

@article{peng2017b,
    title = {{DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning}},
    journal = {ACM Transactions on Graphics},
    author = {Peng, X B and Berseth, G and Yin, K and van de Panne, M},
    number = {4},
    volume = {36},
    publisher = {Proc. SIGGRAPH}
}

@article{beattie2016a,
    title = {{DeepMind Lab}},
    journal = {Sadik, et al},
    edition = {arXiv prep}
}

@article{davis2017a,
    title = {{DeepStack: Expert-level artificial intelligence in heads-up no-limit poker}},
    journal = {Science},
    author = {Davis, K.Waugh and Johanson, M and Bowling, M},
    number = {6337},
    pages = {508–513},
    volume = {356}
}

@misc{fran2016a,
    title = {{DeeR”. https://deer.readthedocs.io/. Fran{\c{c}}ois-Lavet, V.2017.“Contributions to deep reinforcement learning and its applications in smartgrids}},
    author = {Fran{\c{c}}ois-Lavet, V},
    institution = {thesis. University of Liege, Belgium}
}

@article{Kos2017,
    title = {{Delving into adversarial attacks on deep policies}},
    year = {2017},
    journal = {undefined},
    author = {Kos, Jernej and Song, Dawn Xiaodong},
    month = {5},
    url = {http://arxiv.org/abs/1705.06452 https://www.semanticscholar.org/paper/Delving-into-adversarial-attacks-on-deep-policies-Kos-Song/cf8ed2793bc6aec88da5306fe2de560dc0be9b15},
    arxivId = {1705.06452}
}

@book{silver2014a,
    title = {{Deterministic Policy Gradient Algorithms}},
    author = {Silver, D and Lever, G and Heess, N and Degris, T and Wierstra, D and Riedmiller, M},
    publisher = {ICML},
    address = {In}
}

@article{turing1953a,
    title = {{Digital computers applied to games}},
    journal = {Faster than thought},
    author = {Turing, A M}
}

@misc{teh2017a,
    title = {{Distral: Robust Multitask Reinforcement Learning}},
    author = {Teh, Y W and Bapst, V and Czarnecki, W M and Quan, J and Kirkpatrick, J and Hadsell, R and Heess, N and Pascanu, R},
    edition = {arXiv prep}
}

@misc{dabney2017a,
    title = {{Distributional Reinforcement Learning with Quantile Regression}},
    author = {Dabney, W and Rowland, M and Bellemare, M G and Munos, R},
    edition = {arXiv prep}
}

@article{story2014a,
    title = {{Does temporal discounting explain unhealthy behavior? A systematic review and reinforcement learning perspective}},
    journal = {Frontiers in behavioral neuroscience},
    author = {Story, G and Vlaev, I and Seymour, B and Darzi, A and Dolan, R},
    pages = {76},
    volume = {8}
}

@misc{tobin2017a,
    title = {{Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World}},
    author = {Tobin, J and Fong, R and Ray, A and Schneider, J and Zaremba, W and Abbeel, P},
    edition = {arXiv prep}
}

@misc{bellemare2018a,
    title = {{Dopamine}},
    author = {Bellemare, M G and Castro, P S and Gelada, C and Saurabh, K and Moitra, S},
    url = {https://github.com/google/dopamine.}
}

@inproceedings{Hasselt2010,
    title = {{Double Q-learning}},
    year = {2010},
    booktitle = {Neural Information Proceeding Systems},
    author = {Hasselt, Hado Van and Group, Adaptive Computation and Wiskunde, Centrum and Van Hasselt, Hado},
    url = {https://papers.nips.cc/paper/3964-double-q-learning.pdf},
    isbn = {9781617823800},
    doi = {10.1016/j.tws.2009.08.006},
    issn = {02638231},
    pmid = {26150344},
    arxivId = {1606.04615}
}

@inproceedings{jiang2016a,
    title = {{Doubly robust off-policy value evaluation for reinforcement learning}},
    booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
    author = {Jiang, N and Li, L},
    pages = {652–661}
}

@inproceedings{gal2016a,
    title = {{Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning}},
    booktitle = {Proceedings of the 33nd International Conference on Machine Learning, ICML},
    author = {Gal, Y and Ghahramani, Z},
    pages = {1050},
    address = {2016, New York City, NY, USA}
}

@article{srivastava2014a,
    title = {{Dropout: a simple way to prevent neural networks from overfitting.}},
    journal = {Journal of Machine Learning Research},
    author = {Srivastava, N and Hinton, G E and Krizhevsky, A and Sutskever, I and Salakhutdinov, R},
    number = {1},
    pages = {1929–1958},
    volume = {15}
}

@misc{wang2015a,
    title = {{Dueling network architectures for deep reinforcement learning}},
    author = {Wang, Z and de Freitas, N and Lanctot, M},
    edition = {arXiv prep}
}

@incollection{bellman1957a,
    title = {{Dynamic Programming}},
    author = {Bellman, R},
    address = {Bello}
}

@incollection{bertsekas1995a,
    title = {{Dynamic programming and optimal control}},
    author = {Bertsekas, D P and Bertsekas, D P and Bertsekas, D P and Bertsekas, D P},
    number = {2},
    volume = {1},
    address = {Belmont, MA}
}

@misc{lipton2016a,
    title = {{Efficient exploration for dialogue policy learning with BBQ networks {\&} replay buffer spiking}},
    author = {Lipton, Z C and Gao, J and Li, L and Li, X and Ahmed, F and Deng, L},
    edition = {arXiv prep}
}

@incollection{thrun1992a,
    title = {{Efficient exploration in reinforcement learning}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Thrun, S B}
}

@article{moore1990a,
    title = {{Efficient memory-based learning for robot control}},
    journal = {Computers {\&} Chemical Engineering},
    author = {Moore, A W},
    number = {4-5},
    pages = {667–682},
    volume = {23}
}

@article{leffler2007a,
    title = {{Efficient reinforcement learning with relocatable action models}},
    journal = {In: AAAI},
    author = {Leffler, B R and Littman, M L and Edmunds, T},
    pages = {572–577},
    volume = {7}
}

@article{stones,
    title = {{Efficient Search Techniques - An Empirical Study of the N-Queens Problem}},
    year = {1987},
    journal = {IBM Journal of Research and Development},
    author = {Stone, H S and Stone, J M},
    pages = {464--474},
    volume = {31},
    publisher = {International Business Machines.}
}

@book{precup2000a,
    title = {{Eligibility traces for off-policy policy evaluation}},
    author = {Precup, D},
    publisher = {Computer Science Department Faculty Publication Series: 80}
}

@misc{bojarski2016a,
    title = {{End to end learning for self-driving cars}},
    author = {Bojarski, M and Testa, D.Del and Dworakowski, D and Firner, B and Flepp, B and Goyal, P and Jackel, L D and Monfort, M and Muller, U and Zhang, J},
    edition = {arXiv prep}
}

@article{levine2016a,
    title = {{End-to-end training of deep visuomotor policies}},
    journal = {Journal of Machine Learning Research},
    author = {Levine, S and Finn, C and Darrell, T and Abbeel, P},
    number = {39},
    pages = {1–40},
    volume = {17}
}

@misc{savinov2018a,
    title = {{Episodic Curiosity through Reachability}},
    author = {Savinov, N and Raichuk, A and Marinier, R and Vincent, D and Pollefeys, M and Lillicrap, T and Gelly, S},
    edition = {arXiv prep}
}

@misc{schulman2017a,
    title = {{Equivalence Between Policy Gradients and Soft Q-Learning}},
    author = {Schulman, J and Abbeel, P and Chen, X},
    edition = {arXiv prep}
}

@article{Renner2013,
    title = {{Equivalence of MAXENT and Poisson Point Process Models for Species Distribution Modeling in Ecology}},
    year = {2013},
    journal = {Biometrics},
    author = {Renner, Ian W. and Warton, David I.},
    number = {1},
    pages = {274--281},
    volume = {69},
    isbn = {1541-0420},
    doi = {10.1111/j.1541-0420.2012.01824.x},
    issn = {0006341X},
    pmid = {23379623},
    keywords = {Habitat modeling, Location-only, Maximum entropy, Poisson likelihood, Presence-only data, Use-availability}
}

@book{bouckaert2004a,
    title = {{Evaluating the replicability of significance tests for comparing learning algorithms}},
    author = {Bouckaert, R R and Frank, E},
    pages = {3–12},
    publisher = {PAKDD. Springer},
    address = {In}
}

@misc{salimans2017a,
    title = {{Evolution Strategies as a Scalable Alternative to Reinforcement Learning}},
    author = {Salimans, T and Ho, J and Chen, X and Sutskever, I},
    edition = {arXiv prep}
}

@misc{miikkulainen2017a,
    title = {{Evolving Deep Neural Networks}},
    author = {Miikkulainen, R and Liang, J and Meyerson, E and Rawal, A and Fink, D and Francon, O and Raju, B and Navruzyan, A and Duffy, N and Hodjat, B},
    edition = {arXiv prep}
}

@article{Goodfellow2014,
    title = {{Explaining and Harnessing Adversarial Examples}},
    year = {2014},
    author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
    month = {12},
    url = {http://arxiv.org/abs/1412.6572},
    arxivId = {1412.6572}
}

@misc{burda2018a,
    title = {{Exploration by Random Network Distillation}},
    author = {Burda, Y and Edwards, H and Storkey, A and Klimov, O},
    edition = {arXiv prep}
}

@misc{kakade2003a,
    title = {{Exploration in metric state spaces}},
    author = {Kakade, S and Kearns, M and Langford, J},
    editor = {{I.C.M.L.}},
    pages = {306–312},
    volume = {3}
}

@misc{zamora2016a,
    title = {{Extending the OpenAI Gym for robotics: a toolkit for reinforcement learning using ROS and Gazebo}},
    author = {Zamora, I and Lopez, N G and Vilches, V M and Cordero, A H},
    edition = {arXiv prep}
}

@article{geurts2006a,
    title = {{Extremely randomized trees}},
    journal = {Machine learning},
    author = {Geurts, P and Ernst, D and Wehenkel, L},
    number = {1},
    pages = {3–42},
    volume = {63}
}

@incollection{olah2017a,
    title = {{Feature Visualization}},
    author = {Olah, C and Mordvintsev, A and Schubert, L},
    url = {https://distill.pub/2017/feature-visualization.}
}

@article{Fithian2013,
    title = {{Finite-sample equivalence in statistical models for presence-only data}},
    year = {2013},
    journal = {Annals of Applied Statistics},
    author = {Fithian, William and Hastie, Trevor},
    number = {4},
    pages = {1917--1939},
    volume = {7},
    isbn = {1932-6157},
    doi = {10.1214/13-AOAS667},
    issn = {19326157},
    pmid = {25493106},
    arxivId = {1207.6950},
    keywords = {Case-control sampling, Logistic regression, Maximum entropy, Poisson process models, Presence-only data, Species modeling}
}

@article{schmidhuber2010a,
    title = {{Formal theory of creativity, fun, and intrinsic motivation (1990–2010)}},
    journal = {IEEE Transactions on Autonomous Mental Development},
    author = {Schmidhuber, J},
    number = {3},
    pages = {230–247},
    volume = {2}
}

@misc{wahlstroem2015a,
    title = {{From pixels to torques: Policy learning with deep dynamical models}},
    author = {Wahlstr{\"{o}}m, N and Sch{\"{o}}n, T B and Deisenroth, M P},
    edition = {arXiv prep}
}

@incollection{boyan1995a,
    title = {{Generalization in reinforcement learning: Safely approximating the value function}},
    booktitle = {Advances in neural information processing systems},
    author = {Boyan, J A and Moore, A W},
    pages = {369–376}
}

@incollection{ho2016a,
    title = {{Generative adversarial imitation learning}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Ho, J and Ermon, S},
    pages = {4565–4573}
}

@article{lecun1998a,
    title = {{Gradient-based learning applied to document recognition}},
    journal = {Proceedings of the IEEE},
    author = {LeCun, Y and Bottou, L and Bengio, Y and Haffner, P},
    number = {11},
    pages = {2278–2324},
    volume = {86}
}

@inproceedings{finn-a,
    title = {{Guided cost learning: Deep inverse optimal control via policy optimization}},
    booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
    author = {Finn C., S Levine and 2016b, P Abbeel.},
    volume = {48}
}

@incollection{levine2013a,
    title = {{Guided policy search}},
    booktitle = {International Conference on Machine Learning},
    author = {Levine, S and Koltun, V},
    pages = {1–9}
}

@incollection{kulkarni2016a,
    title = {{Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Kulkarni, T D and Narasimhan, K and Saeedi, A and Tenenbaum, J},
    pages = {3675–3683}
}

@inproceedings{hauskrecht1998a,
    title = {{Hierarchical solution of Markov decision processes using macro-actions}},
    booktitle = {Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence},
    author = {Hauskrecht, M and Meuleau, N and Kaelbling, L P and Dean, T and Boutilier, C},
    pages = {220–229},
    publisher = {Morgan Kaufmann Publishers Inc}
}

@misc{gauci2018a,
    title = {{Horizon: Facebook’s Open Source Applied Reinforcement Learning Platform}},
    author = {Gauci, J and Conti, E and Liang, Y and Virochsiri, K and He, Y and Kaden, Z and Narayanan, V and Ye, X},
    edition = {arXiv prep}
}

@article{papad,
    title = {{How Easy is Local Search?}},
    year = {1988},
    journal = {Journal of Computer and System Sciences},
    author = {Johnson, D S and Papadimitrou, C H and Yannakakis, M},
    pages = {79--100},
    volume = {37}
}

@misc{fran2015a,
    title = {{How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies}},
    author = {Fran{\c{c}}ois-Lavet, V and Fonteneau, R and Ernst, D},
    edition = {arXiv prep}
}

@article{Mnih2015,
    title = {{Human-level control through deep reinforcement learning}},
    year = {2015},
    journal = {Nature},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    number = {7540},
    month = {2},
    pages = {529--533},
    volume = {5aaIA18},
    publisher = {Nature Publishing Group},
    url = {http://www.nature.com/articles/nature14236},
    doi = {10.1038/nature14236},
    issn = {0028-0836},
    keywords = {Computer science}
}

@misc{jaderberg2018a,
    title = {{Human-level performance in firstperson multiplayer games with population-based deep reinforcement learning}},
    author = {Jaderberg, M and Czarnecki, W M and Dunning, I and Marris, L and Lever, G and Castaneda, A G and Beattie, C and Rabinowitz, N C and Morcos, A S and Ruderman, A},
    edition = {arXiv prep}
}

@article{russakovsky2015a,
    title = {{Imagenet large scale visual recognition challenge}},
    journal = {International Journal of Computer Vision},
    author = {Russakovsky, O and Deng, J and Su, H and Krause, J and Satheesh, S and Ma, S and Huang, Z and Karpathy, A and Khosla, A and Bernstein, M},
    number = {3},
    pages = {211–252},
    volume = {115}
}

@misc{weber2017a,
    title = {{Imagination-Augmented Agents for Deep Reinforcement Learning}},
    author = {Weber, T and Racani{\`{e}}re, S and Reichert, D P and Buesing, L and Guez, A and Rezende, D J and Badia, A P and Vinyals, O and Heess, N and Li, Y},
    edition = {arXiv prep}
}

@misc{liu2017a,
    title = {{Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation}},
    author = {Liu, Y and Gupta, A and Abbeel, P and Levine, S},
    edition = {arXiv prep}
}

@article{Narasimhan2016,
    title = {{Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning}},
    year = {2016},
    author = {Narasimhan, Karthik and Yala, Adam and Barzilay, Regina},
    month = {3},
    url = {http://arxiv.org/abs/1603.07954},
    arxivId = {1603.07954}
}

@article{Radford,
    title = {{Improving language understanding by generative pre-training}},
    journal = {cs.ubc.ca},
    author = {Radford, A and Narasimhan, K and {\ldots}, T Salimans - URL https://s3-us-west-2 and 2018, undefined},
    url = {https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf}
}

@misc{stadie2015a,
    title = {{Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models}},
    author = {Stadie, B C and Levine, S and Abbeel, P},
    edition = {arXiv prep}
}

@article{szegedy2016a,
    title = {{Inception-v4, inception-resnet and the impact of residual connections on learning}},
    journal = {In: AAAI},
    author = {Szegedy, C and Ioffe, S and Vanhoucke, V and Alemi, A A},
    edition = {arXiv prep},
    number = {12},
    volume = {4}
}

@inproceedings{peng1994a,
    title = {{Incremental multi-step Q-learning}},
    booktitle = {Machine Learning Proceedings},
    author = {Peng, J and Williams, R J},
    pages = {226–232},
    publisher = {Elsevier}
}

@misc{johnson2017a,
    title = {{Inferring and Executing Programs for Visual Reasoning}},
    author = {Johnson, J and Hariharan, B and van der Maaten, L and Hoffman, J and FeiFei, L and Zitnick, C L and Girshick, R},
    edition = {arXiv prep}
}

@incollection{mordatch2015a,
    title = {{Interactive control of diverse complex characters with neural networks}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Mordatch, I and Lowrey, K and Andrew, G and Popovic, Z and Todorov, E V},
    pages = {3132–3140}
}

@misc{macglashan2017a,
    title = {{Interactive Learning from PolicyDependent Human Feedback}},
    author = {MacGlashan, J and Ho, M K and Loftin, R and Peng, B and Roberts, D and Taylor, M E and Littman, M L},
    edition = {arXiv prep}
}

@article{Szegedy2014,
    title = {{Intriguing properties of neural networks}},
    year = {2014},
    journal = {undefined},
    author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian J. and Fergus, Rob},
    url = {https://www.semanticscholar.org/paper/Intriguing-properties-of-neural-networks-Szegedy-Zaremba/83bfdd6a2b28106b9fb66e52832c45f08b828541}
}

@misc{jaques2018a,
    title = {{Intrinsic Social Motivation via Causal Influence in Multi-Agent RL}},
    author = {Jaques, N and Lazaridou, A and Hughes, E and Gulcehre, C and Ortega, P A and Strouse, D and Leibo, J Z and de Freitas, N},
    edition = {arXiv prep}
}

@inproceedings{ginsberg,
    title = {{Iterative Broadening}},
    year = {1990},
    booktitle = {Proceedings of AAAI-91},
    author = {Ginsberg, M L and Harvey, W D}
}

@misc{walsh2017a,
    title = {{It’s Alive!: Artificial Intelligence from the Logic Piano to Killer Robots}},
    author = {Walsh, T}
}

@misc{real2017a,
    title = {{Large-Scale Evolution of Image Classifiers}},
    author = {Real, E and Moore, S and Selle, A and Saxena, S and Suematsu, Y L and Le, Q and Kurakin, A},
    edition = {arXiv prep}
}

@book{stone2000a,
    title = {{Layered learning}},
    author = {Stone, P and Veloso, M},
    pages = {369–381},
    publisher = {Machine Learning: ECML}
}

@misc{riedmiller2018a,
    title = {{Learning by Playing - Solving Sparse Reward Tasks from Scratch}},
    author = {Riedmiller, M and Hafner, R and Lampe, T and Neunert, M and Degrave, J and de Wiele, T.Van and Mnih, V and Heess, N and Springenberg, J T},
    edition = {arXiv prep}
}

@incollection{heess2015a,
    title = {{Learning continuous control policies by stochastic value gradients}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Heess, N and Wayne, G and Silver, D and Lillicrap, T and Erez, T and Tassa, Y},
    pages = {2944–2952}
}

@article{Bengio2009,
    title = {{Learning Deep Architectures for AI}},
    year = {2009},
    journal = {Foundations and Trends{\textregistered} in Machine Learning},
    author = {Bengio, Y.},
    isbn = {2200000006},
    doi = {10.1561/2200000006},
    issn = {1935-8237},
    pmid = {17348934},
    arxivId = {submit/0500581}
}

@techreport{Boyan1998,
    title = {{Learning Evaluation Functions for Global Optimization}},
    year = {1998},
    author = {Boyan, Justin A},
    url = {https://pdfs.semanticscholar.org/61d4/897dbf7ced83a0eb830a8de0dd64abb58ebd.pdf}
}

@book{schulman2016a,
    title = {{Learning from demonstrations through the use of non-rigid registration}},
    author = {Schulman, J and Ho, J and Lee, C and Abbeel, P},
    pages = {339–354},
    publisher = {Robotics Research. Springer},
    address = {In}
}

@inproceedings{branavan2012a,
    title = {{Learning high-level planning from text}},
    booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics},
    author = {Branavan, S and Kushman, N and Lei, T and Barzilay, R},
    pages = {135},
    publisher = {Papers-Volume 1. Association for Computational Linguistics. 126},
    address = {Long}
}

@inproceedings{johnston,
    title = {{Learning in Stochastic Neural Networks for Constraint Satisfaction Problems}},
    year = {1989},
    booktitle = {Proceedings of NASA Conference on Space Telerobotics},
    author = {Johnston, M D and Adorf, H M},
    volume = {37}
}

@misc{pascanu2017a,
    title = {{Learning model-based planning from scratch}},
    author = {Pascanu, R and Li, Y and Vinyals, O and Heess, N and Buesing, L and Racani{\`{e}}re, S and Reichert, D and Weber, T and Wierstra, D and Battaglia, P},
    edition = {arXiv prep}
}

@incollection{sukhbaatar2016a,
    title = {{Learning multiagent communication with backpropagation}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Sukhbaatar, S and Szlam, A and Fergus, R},
    pages = {2244–2252}
}

@misc{chen2017a,
    title = {{Learning Neural Programs To Parse Programs}},
    author = {Chen, X and Liu, C and Song, D},
    edition = {arXiv prep}
}

@article{rumelhart1988a,
    title = {{Learning representations by back-propagating errors}},
    journal = {Cognitive modeling},
    author = {Rumelhart, D E and Hinton, G E and Williams, R J},
    number = {3},
    pages = {1},
    volume = {5}
}

@misc{fazel-zarandi2017a,
    title = {{Learning Robust Dialog Policies in Noisy Environments}},
    author = {Fazel-Zarandi, M and Li, S.-W. and Cao, J and Casale, J and Henderson, P and Whitney, D and Geramifard, A},
    edition = {arXiv prep}
}

@misc{dosovitskiy2016a,
    title = {{Learning to act by predicting the future}},
    author = {Dosovitskiy, A and Koltun, V},
    edition = {arXiv prep}
}

@misc{gandhi2017a,
    title = {{Learning to Fly by Crashing}},
    author = {Gandhi, D and Pinto, L and Gupta, A},
    edition = {arXiv prep}
}

@incollection{hochreiter2001a,
    title = {{Learning to learn using gradient descent}},
    booktitle = {International Conference on Artificial Neural Networks. Springer},
    author = {Hochreiter, S and Younger, A S and Conwell, P R},
    pages = {87–94}
}

@misc{mirowski2016a,
    title = {{Learning to navigate in complex environments}},
    author = {Mirowski, P and Pascanu, R and Viola, F and Soyer, H and Ballard, A and Banino, A and Denil, M and Goroshin, R and Sifre, L and Kavukcuoglu, K},
    edition = {arXiv prep}
}

@misc{haber2018a,
    title = {{Learning to Play with Intrinsically-Motivated Self-Aware Agents}},
    author = {Haber, N and Mrowca, D and Fei-Fei, L and Yamins, D L},
    edition = {arXiv prep}
}

@article{sutton1988a,
    title = {{Learning to predict by the methods of temporal differences}},
    journal = {Machine learning},
    author = {Sutton, R S},
    number = {1},
    pages = {9–44},
    volume = {3}
}

@inproceedings{foerster2018a,
    title = {{Learning with opponent-learning awareness}},
    booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems. International Foundation for Autonomous Agents and Multiagent Systems},
    author = {Foerster, J and Chen, R Y and Al-Shedivat, M and Whiteson, S and Abbeel, P and Mordatch, I},
    pages = {122–130}
}

@techreport{Lagoudakis2003,
    title = {{Least-Squares Policy Iteration}},
    year = {2003},
    booktitle = {Journal of Machine Learning Research},
    author = {Lagoudakis, Michail G and Parr, Ronald},
    pages = {1107--1149},
    volume = {4},
    url = {http://www.jmlr.org/papers/volume4/lagoudakis03a/lagoudakis03a.pdf},
    keywords = {Approximate Policy Iteration, Least-Squares Methods, Markov Decision Processes, Reinforcement Learning, Value-Function Approximation}
}

@incollection{brown2017a,
    title = {{Libratus: The Superhuman AI for No-Limit Poker}},
    booktitle = {International Joint Conference on Artificial Intelligence (IJCAI-17)},
    author = {Brown, N and Sandholm, T}
}

@article{Royle2012,
    title = {{Likelihood analysis of species occurrence probability from presence-only data for modelling species distributions}},
    year = {2012},
    journal = {Methods in Ecology and Evolution},
    author = {Royle, J. Andrew and Chandler, Richard B. and Yackulic, Charles and Nichols, James D.},
    number = {3},
    pages = {545--554},
    volume = {3},
    isbn = {2041-210X},
    doi = {10.1111/j.2041-210X.2011.00182.x},
    issn = {2041210X},
    keywords = {Bayes' rule, Detection probability, Logistic regression, Occupancy model, Occurrence probability, Presence-only data, Species distribution model, maxent}
}

@techreport{Bradtke1996,
    title = {{Linear Least-Squares Algorithms for Temporal Difference Learning}},
    year = {1996},
    author = {Bradtke, Steven J and Barto, Andrew G},
    pages = {33--57},
    volume = {22},
    publisher = {Kluwer Academic Publishers},
    url = {https://link.springer.com/content/pdf/10.1007%2FBF00114723.pdf},
    keywords = {Least-Squares, Markov Decision Problems, Reinforcement learning, Temporal Difference Methods}
}

@article{hochreiter1997a,
    title = {{Long short-term memory}},
    journal = {Neural},
    author = {Hochreiter, S and Schmidhuber, J},
    number = {8},
    pages = {1735–1780},
    volume = {9}
}

@incollection{dietterich2009a,
    title = {{Machine learning and ecosystem informatics: challenges and opportunities}},
    booktitle = {Asian Conference on Machine Learning. Springer},
    author = {Dietterich, T G},
    pages = {1–5}
}

@incollection{murphy2012a,
    title = {{Machine Learning: A Probabilistic Perspective.}},
    author = {Murphy, K P},
    edition = {arXiv prep}
}

@book{norris1998a,
    title = {{Markov chains. No. 2}},
    author = {Norris, J R},
    publisher = {Cambridge university press}
}

@article{jaquette1973a,
    title = {{Markov decision processes with a new optimality criterion: Discrete time}},
    journal = {The Annals of Statistics},
    author = {Jaquette, S C},
    number = {3},
    pages = {496–505},
    volume = {1}
}

@inproceedings{littman1994a,
    title = {{Markov games as a framework for multi-agent reinforcement learning}},
    booktitle = {Proceedings of the eleventh international conference on machine learning},
    author = {Littman, M L},
    pages = {157–163},
    volume = {157}
}

@article{silver2016a,
    title = {{Mastering the game of Go with deep neural networks and tree search}},
    journal = {Nature},
    author = {Silver, D and Huang, A and Maddison, C J and Guez, A and Sifre, L and Driessche, G.Van Den and Schrittwieser, J and Antonoglou, I and Panneershelvam, V and Lanctot, M},
    number = {7587},
    pages = {484–489},
    volume = {529}
}

@article{Silver2017,
    title = {{Mastering the game of Go without human knowledge}},
    year = {2017},
    journal = {Nature},
    author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
    number = {7676},
    month = {10},
    pages = {354--359},
    volume = {550},
    publisher = {Nature Publishing Group},
    url = {http://www.nature.com/doifinder/10.1038/nature24270},
    doi = {10.1038/nature24270},
    issn = {0028-0836},
    keywords = {Computational science, Computer science, Reward}
}

@article{FitzpatrickMCGotelliNJEllison2013,
    title = {{MaxEnt vs. MaxLike: Empirical comparisons with ant species distributions}},
    year = {2013},
    journal = {Ecosphere},
    author = {Fitzpatrick, MC; Gotelli, NJ; Ellison, Am},
    number = {May},
    pages = {1--15},
    volume = {4},
    url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:MaxEnt+versus+MaxLike+:+empirical+comparisons+with+ant+species+distributions#0},
    isbn = {2150-8925},
    doi = {10.1890/es13-00066.1},
    issn = {2150-8925},
    keywords = {ecological niche modeling, myrmecology, new england, occurrence probability, presence-only data, species distribution modeling}
}

@article{Phillips2006,
    title = {{Maximum entropy modeling of species geographic distributions}},
    year = {2006},
    journal = {Ecological Modelling 190 (2006) 231–259},
    author = {Phillips, Steven J and Anderson, Robert P and Schapire, Robert E},
    isbn = {033},
    doi = {10.1016/j.ecolmodel.2005.03.026},
    issn = {14666650},
    pmid = {1474},
    arxivId = {11265},
    keywords = {Ammonia, CMAQ, Dry deposition, Flux, Modelling, Nitrogen, Wet deposition}
}

@inproceedings{dearden1999a,
    title = {{Model based Bayesian exploration}},
    booktitle = {Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence},
    author = {Dearden, R and Friedman, N and Andre, D},
    pages = {150–159},
    publisher = {Morgan Kaufmann Publishers Inc}
}

@misc{finn2017a,
    title = {{Model-agnostic metalearning for fast adaptation of deep networks}},
    author = {Finn, C and Abbeel, P and Levine, S},
    edition = {arXiv prep}
}

@article{Phillips2008,
    title = {{Modeling of species distribution with Maxent: new extensions and a comprehensive evalutation}},
    year = {2008},
    journal = {Ecograpy},
    author = {Phillips, Steven J. and Dud{\'{i}}k, Miroslav},
    number = {December 2007},
    pages = {161--175},
    volume = {31},
    isbn = {0906-7590},
    doi = {10.1111/j.2007.0906-7590.05203.x},
    issn = {0007-1188},
    pmid = {3245},
    arxivId = {10.1111/j.2007.0906-7590.05203.x},
    keywords = {05203, 0906-7590, 10, 1111, 161 {\'{a}} 175, 2007, 2007 at, 2007 ecography, 2008, accepted 13 december 2007, doi, graphy 31, inc, j, jo, journal compilation, t, x}
}

@book{ziebart2010a,
    title = {{Modeling purposeful adaptive behavior with the principle of maximum causal entropy}},
    author = {Ziebart, B D},
    publisher = {Carnegie Mellon University}
}

@misc{gelly2006a,
    title = {{Modification of UCT with patterns in Monte-Carlo Go}},
    author = {Gelly, S and Wang, Y and Munos, R and Teytaud, O}
}

@misc{bruegmann1993a,
    title = {{Monte carlo go}},
    author = {Br{\"{u}}gmann, B}
}

@misc{lowe2017a,
    title = {{Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments}},
    author = {Lowe, R and Wu, Y and Tamar, A and Harb, J and Abbeel, P and Mordatch, I},
    edition = {arXiv prep}
}

@misc{hessel2018a,
    title = {{Multi-task Deep Reinforcement Learning with PopArt}},
    author = {Hessel, M and Soyer, H and Espeholt, L and Czarnecki, W and Schmitt, S and van Hasselt, H},
    edition = {arXiv prep}
}

@misc{peng2017a,
    title = {{Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games}},
    author = {Peng, P and Yuan, Q and Wen, Y and Yang, Y and Tang, Z and Long, H and Wang, J},
    edition = {arXiv prep}
}

@article{amari1998a,
    title = {{Natural Gradient Works Efficiently in Learning}},
    journal = {Neural Computation},
    author = {Amari, S},
    number = {2},
    pages = {251–276},
    volume = {10}
}

@inproceedings{kolter2009a,
    title = {{Near-Bayesian exploration in polynomial time}},
    booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning. ACM},
    author = {Kolter, J Z and Ng, A Y},
    pages = {513–520}
}

@article{kearns2002a,
    title = {{Near-optimal reinforcement learning in polynomial time}},
    journal = {Machine Learning},
    author = {Kearns, M and Singh, S},
    number = {2-3},
    pages = {209–232},
    volume = {49}
}

@misc{chen2015a,
    title = {{Net2net: Accelerating learning via knowledge transfer}},
    author = {Chen, T and Goodfellow, I and Shlens, J},
    edition = {arXiv prep}
}

@misc{zoph2016a,
    title = {{Neural architecture search with reinforcement learning}},
    author = {Zoph, B and Le, Q V},
    edition = {arXiv prep}
}

@article{lee2012a,
    title = {{Neural basis of reinforcement learning and decision making}},
    journal = {Annual review of neuroscience},
    author = {Lee, D and Seo, H and Jung, M W},
    pages = {287–308},
    volume = {35}
}

@book{riedmiller2005a,
    title = {{Neural fitted Q iteration–first experiences with a data efficient neural reinforcement learning method}},
    author = {Riedmiller, M},
    pages = {317–328},
    publisher = {Machine Learning: ECML},
    address = {In}
}

@incollection{nagabandi2018a,
    title = {{Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning}},
    booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE},
    author = {Nagabandi, A and Kahn, G and Fearing, R S and Levine, S},
    pages = {7559–7566}
}

@inproceedings{hopfield,
    title = {{Neural Networks and Physical Systems with Emergent Collective Computational Abilities}},
    year = {1982},
    booktitle = {Proceedings of the National Academy of Sciences},
    author = {Hopfield, J J},
    volume = {79},
    publisher = {Washington, DC: National Academy Press}
}

@article{geman1992a,
    title = {{Neural networks and the bias/variance dilemma}},
    journal = {Neural computation},
    author = {Geman, S and Bienenstock, E and Doursat, R},
    number = {1},
    pages = {1–58},
    volume = {4}
}

@article{nguyen1990a,
    title = {{Neural networks for self-learning control systems}},
    journal = {IEEE Control systems magazine},
    author = {Nguyen, D H and Widrow, B},
    number = {3},
    pages = {18–23},
    volume = {10}
}

@misc{reed2015a,
    title = {{Neural programmer-interpreters}},
    author = {Reed, S and Freitas, N.De},
    edition = {arXiv prep}
}

@misc{neelakantan2015a,
    title = {{Neural programmer: Inducing latent programs with gradient descent}},
    author = {Neelakantan, A and Le, Q V and Sutskever, I},
    edition = {arXiv prep}
}

@misc{graves2014a,
    title = {{Neural turing machines}},
    author = {Graves, A and Wayne, G and Danihelka, I},
    edition = {arXiv prep}
}

@article{camerer2005a,
    title = {{Neuroeconomics: How neuroscience can inform economics}},
    journal = {Journal of economic Literature},
    author = {Camerer, C and Loewenstein, G and Prelec, D},
    number = {1},
    pages = {9–64},
    volume = {43}
}

@article{hassabis2017a,
    title = {{Neuroscience-inspired artificial intelligence}},
    journal = {Neuron},
    author = {Hassabis, D and Kumaran, D and Summerfield, C and Botvinick, M},
    number = {2},
    pages = {245–258},
    volume = {95}
}

@techreport{Watkins1992,
    title = {{No Title}},
    author = {Watkins, Christopher J C H and Dayan, Peter}
}

@article{Phillips2008b,
    title = {{No Title}}
}

@techreport{Watkins1992b,
    title = {{No Title}},
    author = {Watkins, Christopher J C H and Dayan, Peter}
}

@incollection{unknown2001a,
    title = {{No Title}},
    booktitle = {Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, NIPS},
    pages = {1531–1538},
    publisher = {Vancouver, British},
    address = {Columbia, Canada}
}

@misc{kahneman2011a,
    title = {{No Title}},
    author = {Kahneman, D}
}

@article{o2016a,
    title = {{No Title}},
    journal = {Mnih},
    author = {O’Donoghue, B and Munos, R and Kavukcuoglu, K and {V.}}
}

@misc{bostrom2017a,
    title = {{No Title}},
    author = {Bostrom, N}
}

@incollection{jakobi1995a,
    title = {{Noise and the reality gap: The use of simulation in evolutionary robotics}},
    booktitle = {European Conference on Artificial Life. Springer},
    author = {Jakobi, N and Husbands, P and Harvey, I},
    pages = {704–720}
}

@article{fortunato2017a,
    title = {{Noisy networks for exploration}},
    journal = {Pietquin, et al},
    author = {Fortunato, M and Azar, M G and Piot, B and Menick, J and Osband, I and Graves, A and Mnih, V and Munos, R and Hassabis, D and {O.}},
    edition = {arXiv prep}
}

@inproceedings{morimura2010a,
    title = {{Nonparametric return distribution approximation for reinforcement learning}},
    booktitle = {Proceedings of the 27th International Conference on Machine Learning},
    author = {Morimura, T and Sugiyama, M and Kashima, H and Hachiya, H and Tanaka, T},
    pages = {799–806},
    volume = {10}
}

@article{Elith2006a,
    title = {{Novel methods improve prediction of species' distributions from occurrence data}},
    year = {2006},
    journal = {Ecography},
    author = {Elith, J and Graham, C H and Anderson, R P and Dudik, M and Ferrier, S and Guisan, A and Hijmans, R J and Huettmann, F and Leathwick, J R and Lehmann, A and Li, J and Lohmann, L G and Loiselle, B A and Manion, G and Moritz, C and Nakamura, M and Nakazawa, Y and Overton, J M and Peterson, A T and Phillips, S J and Richardson, K and Scachetti-Pereira, R and Schapire, R E and Soberon, J and Williams, S and Wisz, M S and Zimmermann, N E},
    number = {2},
    pages = {129--151},
    volume = {29},
    isbn = {1600-0587},
    doi = {10.1111/j.2006.0906-7590.04596.x},
    issn = {09067590},
    pmid = {1891},
    arxivId = {arXiv:1011.1669v3},
    keywords = {biodiversity, climate-change, conservation, distribution models, envelope models, habitat-suitability, logistic-regression, plant, potential distribution, spatial prediction}
}

@misc{fran2017a,
    title = {{On overfitting and asymptotic bias in batch reinforcement learning with partial observability}},
    author = {Fran{\c{c}}ois-Lavet, V and Ernst, D and Raphael, F},
    edition = {arXiv prep}
}

@misc{paine2018a,
    title = {{One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL}},
    author = {Paine, T L and Colmenarejo, S G and Wang, Z and Reed, S and Aytar, Y and Pfaff, T and Hoffman, M W and Barth-Maron, G and Cabi, S and Budden, D},
    edition = {arXiv prep}
}

@misc{duan2017a,
    title = {{One-Shot Imitation Learning}},
    author = {Duan, Y and Andrychowicz, M and Stadie, B and Ho, J and Schneider, J and Sutskever, I and Abbeel, P and Zaremba, W},
    edition = {arXiv prep}
}

@article{dhariwal2017a,
    title = {{OpenAI Baselines}},
    journal = {Neural computation},
    author = {Dhariwal, P and Hesse, C and Plappert, M and Radford, A and Schulman, J and Sidor, S and Wu, Y},
    number = {7},
    pages = {1895–1923},
    volume = {10}
}

@misc{brockman2016a,
    title = {{OpenAI Gym}},
    author = {Brockman, G and Cheung, V and Pettersson, L and Schneider, J and Schulman, J and Tang, J and Zaremba, W}
}

@article{And2018,
    title = {{Optimization of Control Measures Against Invasive Species BY Andreas Lydakis PROJECT Submitted to the University of New Hampshire In Partial Fulfilment of Master of Science in Computer Science February , 2018 Dr Marek Petik ( supervisor )}},
    year = {2018},
    author = {Lydakis, Andreas}
}

@misc{kirkpatrick2016a,
    title = {{Overcoming catastrophic forgetting in neural networks}},
    author = {Kirkpatrick, J and Pascanu, R and Rabinowitz, N and Veness, J and Desjardins, G and Rusu, A A and Milan, K and Quan, J and Ramalho, T and Grabska-Barwinska, A},
    edition = {arXiv prep}
}

@techreport{AlkaeeTaleghan2015a,
    title = {{PAC Optimal MDP Planning with Application to Invasive Species Management *}},
    year = {2015},
    booktitle = {Journal of Machine Learning Research},
    author = {Alkaee Taleghan, Majid and Dietterich, Thomas G and Crowley, Mark and Hall, Kim and Jo Albers, H and Auer, Peter and Hutter, Marcus and Orseau, Laurent},
    pages = {3877--3903},
    volume = {16},
    url = {http://jmlr.org/papers/volume16/taleghan15a/taleghan15a.pdf},
    keywords = {Good-Turing estimate, MDP planning, Markov decision processes, invasive species management, reinforcement learning}
}

@misc{plappert2017a,
    title = {{Parameter Space Noise for Exploration}},
    author = {Plappert, M and Houthooft, R and Dhariwal, P and Sidor, S and Chen, R Y and Chen, X and Asfour, T and Abbeel, P and Andrychowicz, M},
    edition = {arXiv prep}
}

@article{Nogueira2019,
    title = {{Passage Re-ranking with BERT}},
    year = {2019},
    author = {Nogueira, Rodrigo and Cho, Kyunghyun},
    month = {1},
    url = {http://arxiv.org/abs/1901.04085},
    arxivId = {1901.04085}
}

@book{christopher2006a,
    title = {{Pattern recognition and machine learning}},
    author = {Christopher, M B},
    publisher = {Springer}
}

@article{Dudik2004a,
    title = {{Performance Guarantees for Regularized Maximum Entropy Density Estimation}},
    year = {2004},
    author = {Dud{\'{i}}k, Miroslav and Phillips, Steven J. and Schapire, Robert E.},
    pages = {472--486},
    url = {http://link.springer.com/10.1007/978-3-540-27819-1_33},
    isbn = {0302-9743},
    doi = {10.1007/978-3-540-27819-1{\_}33},
    issn = {03029743},
    pmid = {6185}
}

@article{kaelbling1998a,
    title = {{Planning and acting in partially observable stochastic domains}},
    journal = {Artificial},
    author = {Kaelbling, L P and Littman, M L and Cassandra, A R},
    number = {1},
    pages = {99–134},
    volume = {101}
}

@incollection{sun2011a,
    title = {{Planning to be surprised: Optimal bayesian exploration in dynamic environments}},
    booktitle = {Artificial General Intelligence. Springer},
    author = {Sun, Y and Gomez, F and Schmidhuber, J},
    pages = {41–51}
}

@misc{aytar2018a,
    title = {{Playing hard exploration games by watching YouTube}},
    author = {Aytar, Y and Pfaff, T and Budden, D and Paine, T L and Wang, Z and de Freitas, N},
    edition = {arXiv prep}
}

@article{Warton2010,
    title = {{POISSON POINT PROCESS MODELS SOLVE THE "PSEUDO-ABSENCE PROBLEM" FOR PRESENCE-ONLY DATA IN ECOLOGY 1}},
    year = {2010},
    journal = {The Annals of Applied Statistics},
    author = {Warton, David I and Shepherd, Leah C},
    number = {3},
    pages = {1383--1402},
    volume = {4},
    url = {https://projecteuclid.org/download/pdfview_1/euclid.aoas/1287409378},
    doi = {10.1214/10-AOAS331},
    keywords = {Habitat modeling, occurrence data, pseudo-absences, quadrature points, species distribution modeling}
}

@article{Warton2010b,
    title = {{POISSON POINT PROCESS MODELS SOLVE THE {\&}quot;PSEUDO-ABSENCE PROBLEM{\&}quot; FOR PRESENCE-ONLY DATA IN ECOLOGY 1}},
    year = {2010},
    journal = {The Annals of Applied Statistics},
    author = {Warton, David I and Shepherd, Leah C},
    number = {3},
    pages = {1383--1402},
    volume = {4},
    url = {https://projecteuclid.org/download/pdfview_1/euclid.aoas/1287409378},
    doi = {10.1214/10-AOAS331},
    keywords = {Habitat modeling, occurrence data, pseudo-absences, quadrature points, species distribution modeling}
}

@misc{rusu2015a,
    title = {{Policy distillation}},
    author = {Rusu, A A and Colmenarejo, S G and Gulcehre, C and Desjardins, G and Kirkpatrick, J and Pascanu, R and Mnih, V and Kavukcuoglu, K and Hadsell, R},
    edition = {arXiv prep}
}

@misc{ng1999a,
    title = {{Policy invariance under reward transformations: Theory and application to reward shaping}},
    author = {Ng, A Y and Harada, D and Russell, S},
    editor = {{I.C.M.L.}},
    pages = {278–287},
    volume = {99}
}

@techreport{braziunas2003a,
    title = {{POMDP solution methods}},
    author = {Braziunas, D},
    institution = {University of Toronto, Tech. Rep}
}

@article{Papernot2016,
    title = {{Practical Black-Box Attacks against Machine Learning}},
    year = {2016},
    journal = {ACM Asia Conference on Computer and Communications Security},
    author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
    url = {http://arxiv.org/abs/1602.02697},
    isbn = {978-1-4503-4944-4},
    doi = {10.1145/3052973.3053009},
    issn = {1998-4049},
    pmid = {21546725},
    arxivId = {1602.02697}
}

@book{russek2017a,
    title = {{Predictive representations can link model-based reinforcement learning to model-free mechanisms}},
    author = {Russek, E M and Momennejad, I and Botvinick, M M and Gershman, S J and Daw, N D},
    publisher = {bioRxiv: 083857}
}

@article{Ward2009,
    title = {{Presence-Only Data and the EM Algorithm}},
    year = {2009},
    journal = {Biometrics},
    author = {Ward, Gill and Hastie, Trevor and Barry, Simon and Elith, Jane and Leathwick, John R.},
    number = {2},
    month = {6},
    pages = {554--563},
    volume = {65},
    publisher = {Wiley/Blackwell (10.1111)},
    url = {http://doi.wiley.com/10.1111/j.1541-0420.2008.01116.x},
    doi = {10.1111/j.1541-0420.2008.01116.x},
    issn = {0006341X},
    keywords = {Boosted trees, EM algorithm, Logistic model, Presence‐only data, Use‐availability data}
}

@misc{schaul2015a,
    title = {{Prioritized Experience Replay}},
    author = {Schaul, T and Quan, J and Antonoglou, I and Silver, D},
    edition = {arXiv prep}
}

@misc{schulman2017b,
    title = {{Proximal policy optimization algorithms}},
    author = {Schulman, J and Wolski, F and Dhariwal, P and Radford, A and Klimov, O},
    edition = {arXiv prep}
}

@article{bubeck2011a,
    title = {{Pure exploration in finitely-armed and continuous-armed bandits}},
    journal = {Theoretical Computer Science},
    author = {Bubeck, S and Munos, R and Stoltz, G},
    number = {19},
    pages = {1832–1852},
    volume = {412}
}

@article{schaul2010a,
    title = {{PyBrain}},
    journal = {The Journal of Machine Learning Research},
    author = {Schaul, T and Bayer, J and Wierstra, D and Sun, Y and Felder, M and Sehnke, F and R{\"{u}}ckstie{\ss}, T and Schmidhuber, J},
    pages = {743–746},
    volume = {11}
}

@book{unknown-ab,
    title = {{Q ({$\lambda$}) with Off-Policy Corrections”. In: International Conference on Algorithmic Learning Theory}},
    pages = {305–320},
    publisher = {Springer}
}

@article{watkins1992a,
    title = {{Q-learning}},
    journal = {Machine learning},
    author = {Watkins, C J and Dayan, P},
    number = {3-4},
    pages = {279–292},
    volume = {8}
}

@misc{kalashnikov2018a,
    title = {{Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation}},
    author = {Kalashnikov, D and Irpan, A and Pastor, P and Ibarz, J and Herzog, A and Jang, E and Quillen, D and Holly, E and Kalakrishnan, M and Vanhoucke, V and Levine, S},
    edition = {arXiv prep}
}

@article{Kuzi,
    title = {{Query Expansion Using Word Embeddings}},
    author = {Kuzi, Saar and Shtok, Anna and Kurland, Oren},
    url = {http://dx.doi.org/10.1145/2983323.2983876},
    isbn = {9781450340731},
    doi = {10.1145/2983323.2983876}
}

@article{brafman2003a,
    title = {{R-max-a general polynomial time algorithm for near-optimal reinforcement learning}},
    journal = {The Journal of Machine Learning Research},
    author = {Brafman, R I and Tennenholtz, M},
    pages = {213–231},
    volume = {3}
}

@article{bartlett2002a,
    title = {{Rademacher and Gaussian complexities: Risk bounds and structural results}},
    journal = {Journal of Machine Learning Research},
    author = {Bartlett, P L and Mendelson, S},
    pages = {463–482},
    volume = {3}
}

@misc{hessel2017a,
    title = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
    author = {Hessel, M and Modayil, J and van Hasselt, H and Schaul, T and Ostrovski, G and Dabney, W and Horgan, D and Piot, B and Azar, M and Silver, D},
    edition = {arXiv prep}
}

@misc{chiappa2017a,
    title = {{Recurrent Environment Simulators}},
    author = {Chiappa, S and Racaniere, S and Wierstra, D and Mohamed, S},
    edition = {arXiv prep}
}

@misc{li2015a,
    title = {{Recurrent reinforcement learning: a hybrid approach}},
    author = {Li, X and Li, L and Gao, J and He, X and Chen, J and Deng, L and He, J},
    edition = {arXiv prep}
}

@article{hafner2011a,
    title = {{Reinforcement learning in feedback control}},
    journal = {Machine learning},
    author = {Hafner, R and Riedmiller, M},
    number = {1-2},
    pages = {137–169},
    volume = {84}
}

@article{niv2009a,
    title = {{Reinforcement learning in the brain}},
    journal = {Journal of Mathematical Psychology},
    author = {Niv, Y},
    number = {3},
    pages = {139–154},
    volume = {53}
}

@incollection{montague2013a,
    title = {{Reinforcement Learning Models Then-andNow: From Single Cells to Modern Neuroimaging}},
    author = {Montague, P R},
    pages = {271–277},
    publisher = {Springer}
}

@misc{haarnoja2017a,
    title = {{Reinforcement learning with deep energy-based policies}},
    author = {Haarnoja, T and Tang, H and Abbeel, P and Levine, S},
    edition = {arXiv prep}
}

@article{singh1996a,
    title = {{Reinforcement learning with replacing eligibility traces}},
    journal = {Machine learning},
    author = {Singh, S P and Sutton, R S},
    number = {1-3},
    pages = {123–158},
    volume = {22}
}

@misc{mccallum1996a,
    title = {{Reinforcement learning with selective perception and hidden state}},
    author = {McCallum, A K},
    institution = {thesis. University of Rochester}
}

@misc{jaderberg2016a,
    title = {{Reinforcement learning with unsupervised auxiliary tasks}},
    author = {Jaderberg, M and Mnih, V and Czarnecki, W M and Schaul, T and Leibo, J Z and Silver, D and Kavukcuoglu, K},
    edition = {arXiv prep}
}

@book{sutton1998a,
    title = {{Reinforcement learning: An introduction}},
    author = {Sutton, R S and Barto, A G},
    number = {1},
    volume = {1},
    publisher = {MIT press Cambridge}
}

@book{sutton2017a,
    title = {{Reinforcement Learning: An Introductionin progress)}},
    author = {Sutton, R S and Barto, A G},
    edition = {2},
    publisher = {MIT Press}
}

@incollection{dayan2008b,
    title = {{Reinforcement learning: the good, the bad and the ugly}},
    booktitle = {Current opinion in neurobiology},
    author = {Dayan, P and Niv, Y},
    number = {2},
    pages = {185–196},
    volume = {18}
}

@article{d2001a,
    title = {{Relational reinforcement learning}},
    journal = {Machine learning},
    author = {D{\v{z}}eroski, S and Raedt, L.De and Driessens, K},
    number = {1-2},
    pages = {7–52},
    volume = {43}
}

@inproceedings{Lavrenko2001,
    title = {{Relevance based language models}},
    year = {2001},
    booktitle = {Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval  - SIGIR '01},
    author = {Lavrenko, Victor and Croft, W. Bruce},
    pages = {120--127},
    publisher = {ACM Press},
    url = {http://portal.acm.org/citation.cfm?doid=383952.383972},
    address = {New York, New York, USA},
    isbn = {1581133316},
    doi = {10.1145/383952.383972}
}

@incollection{islam2017a,
    title = {{Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control}},
    booktitle = {ICML Reproducibility in Machine Learning Workshop},
    author = {Islam, R and Henderson, P and Gomrokchi, M and Precup, D}
}

@misc{casadevall2010a,
    title = {{Reproducible science}},
    author = {Casadevall, A and Fang, F C}
}

@misc{machado2017a,
    title = {{Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents}},
    author = {Machado, M C and Bellemare, M G and Talvitie, E and Veness, J and Hausknecht, M and Bowling, M},
    edition = {arXiv prep}
}

@article{tanner2009a,
    title = {{RL-Glue: Language-independent software for reinforcement-learning experiments}},
    journal = {The Journal of Machine Learning Research},
    author = {Tanner, B and White, A},
    pages = {2133–2136},
    volume = {10}
}

@article{geramifard2015a,
    title = {{RLPy: A Value-Function-Based Reinforcement Learning Framework for Education and Research}},
    journal = {Journal of Machine Learning Research},
    author = {Geramifard, A and Dann, C and Klein, R H and Dabney, W and How, J P},
    pages = {1573–1578},
    volume = {16}
}

@article{Pattanaik2018,
    title = {{Robust Deep Reinforcement Learning with Adversarial Attacks}},
    year = {2018},
    journal = {undefined},
    author = {Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
    url = {https://www.semanticscholar.org/paper/Robust-Deep-Reinforcement-Learning-with-Adversarial-Pattanaik-Tang/3b6c891fbccaa564ea4fd8914a5e3952fcf42ee3}
}

@article{Iyengar2005,
    title = {{Robust Dynamic Programming}},
    year = {2005},
    journal = {Robust Dynamic Programming. Mathematics of Operations Research},
    author = {Iyengar, Garud N},
    number = {2},
    pages = {257--280},
    volume = {30},
    url = {http://pubsonline.informs.org.https//doi.org/10.1287/moor.1040.0129http://www.informs.orghttp://www.columbia.edu/∼gi10},
    doi = {10.1287/moor.1040.0129},
    issn = {1526-5471},
    keywords = {90C25 OR/MS subject classificati, Markov decision processes, ambiguity MSC2000 subject classification: Primary:, dynamic programming, robust optimization, secondary: 90C40, secondary: probability-Markov processes}
}

@article{Lydakis2018,
    title = {{Robust strategies for managing invasive plants}},
    year = {2018},
    journal = {IJCAI Artificial Intelligence for Wildlife Conservation},
    author = {Lydakis, Andreas and Allen, Jenica M. and Petrik, Marek and Szewczyk, Tim M.}
}

@incollection{munos2016a,
    title = {{Safe and efficient off-policy reinforcement learning}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Munos, R and Stepleton, T and Harutyunyan, A and Bellemare, M},
    pages = {1046–1054}
}

@misc{wang2016a,
    title = {{Sample efficient actor-critic with experience replay}},
    author = {Wang, Z and Bapst, V and Heess, N and Mnih, V and Munos, R and Kavukcuoglu, K and de Freitas, N},
    edition = {arXiv prep}
}

@misc{guo2017a,
    title = {{Sample efficient feature selection for factored mdps}},
    author = {Guo, Z D and Brunskill, E},
    edition = {arXiv prep}
}

@article{Phillips2009,
    title = {{Sample selection bias and presence-only distribution models : implications for background and pseudo-absence data Reference Sample selection bias and presence-only distribution models : implications for background and pseudo-absence data}},
    year = {2009},
    journal = {Ecological Applications},
    author = {Phillips, S. J.},
    number = {1},
    pages = {181--197},
    volume = {19},
    isbn = {1051-0761},
    doi = {10.1890/07-2153.1},
    issn = {1051-0761},
    pmid = {19323182},
    arxivId = {1132},
    keywords = {background data, niche modeling, presence-only distribution models, pseudo-absence, sample selection bias, species distribution modeling, target group}
}

@misc{harari2014a,
    title = {{Sapiens: A brief history of humankind}},
    author = {Harari, Y N}
}

@misc{kansky2017a,
    title = {{Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics}},
    edition = {arXiv prep}
}

@article{pedregosa2011a,
    title = {{Scikit-learn: Machine learning in Python}},
    journal = {Journal of Machine Learning Research},
    author = {Pedregosa, F and Varoquaux, G and Gramfort, A and Michel, V and Thirion, B and Grisel, O and Blondel, M and Prettenhofer, P and Weiss, R and Dubourg, V},
    pages = {2825–2830},
    volume = {12}
}

@article{lin1992a,
    title = {{Self-improving reactive agents based on reinforcement learning, planning and teaching}},
    journal = {Machine learning},
    author = {Lin, L.-J.},
    number = {3-4},
    pages = {293–321},
    volume = {8}
}

@misc{klambauer2017a,
    title = {{SelfNormalizing Neural Networks}},
    author = {Klambauer, G and Unterthiner, T and Mayr, A and Hochreiter, S},
    edition = {arXiv prep}
}

@misc{ranzato2015a,
    title = {{Sequence level training with recurrent neural networks}},
    author = {Ranzato, M and Chopra, S and Auli, M and Zaremba, W},
    edition = {arXiv prep}
}

@article{cohen2007a,
    title = {{Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration}},
    journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
    author = {Cohen, J D and McClure, S M and Angela, J Y},
    number = {1481},
    pages = {933–942},
    volume = {362}
}

@incollection{xu2015a,
    title = {{Show, attend and tell: Neural image caption generation with visual attention}},
    booktitle = {International Conference on Machine Learning},
    author = {Xu, K and Ba, J and Kiros, R and Cho, K and Courville, A and Salakhudinov, R and Zemel, R and Bengio, Y},
    pages = {2048–2057}
}

@misc{rusu2016a,
    title = {{Sim-to-real robot learning from pixels with progressive nets}},
    edition = {arXiv prep}
}

@misc{tan2018a,
    title = {{Sim-to-Real: Learning Agile Locomotion For Quadruped Robots}},
    author = {Tan, J and Zhang, T and Coumans, E and Iscen, A and Bai, Y and Hafner, D and Bohez, S and Vanhoucke, V},
    edition = {arXiv prep}
}

@article{williams1992a,
    title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
    journal = {Machine learning},
    author = {Williams, R J},
    number = {3-4},
    pages = {229–256},
    volume = {8}
}

@inproceedings{min-aaai,
    title = {{Solving Large Scale Constraint Satisfaction and Scheduling Problems Using a Heuristic Repair Method}},
    year = {1990},
    booktitle = {Proceedings of AAAI-90},
    author = {Minton, S and Johnston, M and Philips, A B and Laird, P}
}

@article{samuel1959a,
    title = {{Some studies in machine learning using the game of checkers}},
    journal = {IBM Journal of research and development},
    author = {Samuel, A L},
    number = {3},
    pages = {210–229},
    volume = {3}
}

@inproceedings{narvekar2016a,
    title = {{Source task creation for curriculum learning}},
    booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents {\&} Multiagent Systems. International Foundation for Autonomous Agents and Multiagent Systems},
    author = {Narvekar, S and Sinapov, J and Leonetti, M and Stone, P},
    pages = {566–574}
}

@misc{foerster2017b,
    title = {{Stabilising experience replay for deep multi-agent reinforcement learning}},
    author = {Foerster, J and Nardelli, N and Farquhar, G and Torr, P and Kohli, P and Whiteson, S},
    edition = {arXiv prep}
}

@article{vinyals2017a,
    title = {{StarCraft II: A New Challenge for Reinforcement Learning}},
    journal = {Schrittwieser, et al},
    author = {Vinyals, O and Ewalds, T and Bartunov, S and Georgiev, P and Vezhnevets, A S and Yeo, M and Makhzani, A and K{\"{u}}ttler, H and Agapiou, J and {J.}},
    edition = {arXiv prep}
}

@article{dem2006a,
    title = {{Statistical comparisons of classifiers over multiple data sets}},
    journal = {Journal of Machine learning research},
    author = {Dem{\v{s}}ar, J},
    pages = {1–30},
    volume = {7}
}

@misc{vapnik1998a,
    title = {{Statistical learning theory. Adaptive and learning systems for signal processing, communications, and control}},
    author = {Vapnik, V N}
}

@misc{florensa2017a,
    title = {{Stochastic neural networks for hierarchical reinforcement learning}},
    author = {Florensa, C and Duan, Y and Abbeel, P},
    edition = {arXiv prep}
}

@incollection{vezhnevets2016a,
    title = {{Strategic attentive writer for learning macro-actions}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Vezhnevets, A and Mnih, V and Osindero, S and Graves, A and Vinyals, O and Agapiou, J},
    pages = {3486–3494}
}

@article{cortes1995a,
    title = {{Support-vector networks}},
    journal = {Machine learning},
    author = {Cortes, C and Vapnik, V},
    number = {3},
    pages = {273–297},
    volume = {20}
}

@techreport{Sutton1998,
    title = {{Sutton {\&} Barto Book: Reinforcement Learning: An Introduction}},
    year = {1998},
    booktitle = {MIT press},
    author = {Sutton, Richard S. and Barto, Andrew G.},
    isbn = {0262193981},
    doi = {10.1109/TNN.1998.712192},
    issn = {10459227},
    pmid = {18255791},
    arxivId = {1603.02199},
    keywords = {reinforcement learning theory}
}

@inproceedings{langley,
    title = {{Systematic and Nonsystematic Search Strategies}},
    year = {1992},
    booktitle = {Proceedings of AAAI-92},
    author = {Langley, P}
}

@techreport{Lin2017,
    title = {{Tactics of Adversarial Attack on Deep Reinforcement Learning Agents}},
    year = {2017},
    author = {Lin, Yen-Chen and Hong, Zhang-Wei and Liao, Yuan-Hong and Shih, Meng-Li and Liu, Ming-Yu and Sun, Min},
    url = {https://www.ijcai.org/proceedings/2017/0525.pdf},
    keywords = {Machine Learning: Deep Learning, Machine Learning: New Problems, Machine Learning: Reinforcement Learning, Multidisciplinary Topics and Applications: AI{\&}Secu}
}

@misc{fox2015a,
    title = {{Taming the noise in reinforcement learning via soft updates}},
    author = {Fox, R and Pakman, A and Tishby, N},
    edition = {arXiv prep}
}

@misc{zhu2016a,
    title = {{Target-driven visual navigation in indoor scenes using deep reinforcement learning}},
    author = {Zhu, Y and Mottaghi, R and Kolve, E and Lim, J J and Gupta, A and FeiFei, L and Farhadi, A},
    edition = {arXiv prep}
}

@article{Nogueira2017,
    title = {{Task-Oriented Query Reformulation with Reinforcement Learning}},
    year = {2017},
    author = {Nogueira, Rodrigo and Cho, Kyunghyun},
    month = {4},
    url = {http://arxiv.org/abs/1704.04572},
    arxivId = {1704.04572}
}

@article{Miller2012,
    title = {{Tax Collections Optimization for New York State}},
    year = {2012},
    author = {Miller, Gerard and Weatherwax, Melissa and Gardinier, Timothy and Abe, Naoki and Melville, Prem and Pendus, Cezar and Jensen, David and Reddy, Chandan K and Thomas, Vince and Bennett, James and Anderson, Gary and Cooley, Brent},
    url = {http://pubsonline.informs.org74-84.https//doi.org/10.1287/inte.1110.0618http://www.informs.org},
    doi = {10.1287/inte.1110.0618}
}

@misc{matiisen2017a,
    title = {{TeacherStudent Curriculum Learning}},
    author = {Matiisen, T and Oliver, A and Cohen, T and Schulman, J},
    edition = {arXiv prep}
}

@techreport{Watkins1992c,
    title = {{Technical Note Q,-Learning}},
    year = {1992},
    author = {Watkins, Christopher J C H and Dayan, Peter},
    pages = {279--292},
    volume = {8},
    url = {http://www.gatsby.ucl.ac.uk/~dayan/papers/cjch.pdf},
    keywords = {Q-learning, asynchronous dynamic programming, reinforcement learning, temporal differences}
}

@article{papernot2016technical,
    title = {{Technical Report on the CleverHans v2.1.0 Adversarial Examples Library}},
    year = {2016},
    author = {Papernot, Nicolas and Faghri, Fartash and Carlini, Nicholas and Goodfellow, Ian and Feinman, Reuben and Kurakin, Alexey and Xie, Cihang and Sharma, Yash and Brown, Tom and Roy, Aurko and Matyasko, Alexander and Behzadan, Vahid and Hambardzumyan, Karen and Zhang, Zhishuai and Juang, Yi-Lin and Li, Zhi and Sheatsley, Ryan and Garg, Abhibhav and Uesato, Jonathan and Gierke, Willi and Dong, Yinpeng and Berthelot, David and Hendricks, Paul and Rauber, Jonas and Long, Rujun and McDaniel, Patrick},
    month = {10},
    url = {http://arxiv.org/abs/1610.00768},
    arxivId = {1610.00768}
}

@misc{sutton1984a,
    title = {{Temporal credit assignment in reinforcement learning}},
    author = {Sutton, R S}
}

@article{tesauro1995a,
    title = {{Temporal difference learning and TD-Gammon}},
    journal = {Communications of the ACM},
    author = {Tesauro, G},
    number = {3},
    pages = {58–68},
    volume = {38}
}

@incollection{schraudolph1994a,
    title = {{Temporal difference learning of position evaluation in the game of Go}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Schraudolph, N N and Dayan, P and Sejnowski, T J},
    pages = {817–824}
}

@article{sandve2013a,
    title = {{Ten simple rules for reproducible computational research}},
    journal = {PLoS computational biology},
    author = {Sandve, G K and Nekrutenko, A and Taylor, J and Hovig, E},
    number = {10},
    pages = {1003285},
    volume = {9}
}

@article{abadi2016a,
    title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
    journal = {Devin, et al},
    author = {Abadi, M and Agarwal, A and Barham, P and Brevdo, E and Chen, Z and Citro, C and Corrado, G S and Davis, A and Dean, J and {M.}},
    edition = {arXiv prep}
}

@misc{schaarschmidt2017a,
    title = {{TensorForce: A TensorFlow library for applied reinforcement learning}},
    author = {Schaarschmidt, M and Kuhnle, A and Fricke, K}
}

@article{perez-liebana2016a,
    title = {{The 2014 general video game playing competition}},
    journal = {IEEE Transactions on Computational Intelligence and AI in Games},
    author = {Perez-Liebana, D and Samothrakis, S and Togelius, J and Schaul, T and Lucas, S M and Cou{\"{e}}toux, A and Lee, J and Lim, C.-U. and Thompson, T},
    number = {3},
    pages = {229–243},
    volume = {8}
}

@article{bellemare2013a,
    title = {{The Arcade Learning Environment: An evaluation platform for general agents.}},
    journal = {Journal of Artificial Intelligence Research},
    author = {Bellemare, M G and Naddaf, Y and Veness, J and Bowling, M},
    pages = {253–279},
    volume = {47}
}

@misc{bengio2017a,
    title = {{The Consciousness Prior}},
    author = {Bengio, Y},
    edition = {arXiv prep}
}

@inproceedings{jiang-b,
    title = {{The Dependence of Effective Planning Horizon on Model Accuracy}},
    booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems. International Foundation for}
}

@article{halsey2015a,
    title = {{The fickle P value generates irreproducible results}},
    journal = {Nature methods},
    author = {Halsey, L G and Curran-Everett, D and Vowler, S L and Drummond, G B},
    number = {3},
    pages = {179–185},
    volume = {12}
}

@misc{brundage2018a,
    title = {{The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation}},
    author = {Brundage, M and Avin, S and Clark, J and Toner, H and Eckersley, P and Garfinkel, B and Dafoe, A and Scharre, P and Zeitzoff, T and Filar, B},
    edition = {arXiv prep}
}

@article{holroyd2002a,
    title = {{The neural basis of human error processing: reinforcement learning, dopamine, and the error-related negativity.}},
    journal = {Psychological review},
    author = {Holroyd, C B and Coles, M G},
    number = {4},
    pages = {679},
    volume = {109}
}

@article{sondik1978a,
    title = {{The optimal control of partially observable Markov processes over the infinite horizon: Discounted costs}},
    journal = {Operations research},
    author = {Sondik, E J},
    number = {2},
    pages = {282–304},
    volume = {26}
}

@misc{bacon2016a,
    title = {{The option-critic architecture}},
    author = {Bacon, P.-L. and Harb, J and Precup, D},
    edition = {arXiv prep}
}

@misc{silver2016b,
    title = {{The predictron: End-to-end learning and planning}},
    author = {Silver, D and van Hasselt, H and Hessel, M and Schaul, T and Guez, A and Harley, T and Dulac-Arnold, G and Reichert, D and Rabinowitz, N and Barreto, A},
    edition = {arXiv prep}
}

@misc{gruslys2017a,
    title = {{The Reactor: A Sample-Efficient Actor-Critic Architecture}},
    author = {Gruslys, A and Azar, M G and Bellemare, M G and Munos, R},
    edition = {arXiv prep}
}

@book{niv2009b,
    title = {{Theoretical and empirical studies of learning}},
    author = {Niv, Y and Montague, P R},
    pages = {331–351},
    publisher = {Neuroeconomics. Elsevier},
    address = {In}
}

@misc{synnaeve2016a,
    title = {{TorchCraft: a Library for Machine Learning Research on Real-Time Strategy Games}},
    author = {Synnaeve, G and Nardelli, N and Auvolat, A and Chintala, S and Lacroix, T and Lin, Z and Richoux, F and Usunier, N},
    edition = {arXiv prep}
}

@misc{bengio2015a,
    title = {{Towards biologically plausible deep learning}},
    author = {Bengio, Y and Lee, D.-H. and Bornschein, J and Mesnard, T and Lin, Z},
    edition = {arXiv prep}
}

@misc{garnelo2016a,
    title = {{Towards Deep Symbolic Reinforcement Learning}},
    author = {Garnelo, M and Arulkumaran, K and Shanahan, M},
    edition = {arXiv prep}
}

@article{li2016a,
    title = {{Traffic signal timing via deep reinforcement learning}},
    journal = {IEEE/CAA Journal of Automatica Sinica},
    author = {Li, L and Lv, Y and Wang, F.-Y.},
    number = {3},
    pages = {247–254},
    volume = {3}
}

@misc{wu2016a,
    title = {{Training agent for first-person shooter game with actor-critic curriculum learning}},
    author = {Wu, Y and Tian, Y}
}

@techreport{Dietz,
    title = {{TREC Complex Answer Retrieval Overview}},
    year = {2017},
    booktitle = {Trec},
    author = {Dietz, Laura and Verma, Manisha and Radlinski, Filip and Craswell, Nick},
    pages = {1--13},
    url = {http://trec-car.cs.unh.edu}
}

@incollection{ernst2005a,
    title = {{Tree-based batch mode reinforcement learning}},
    booktitle = {Journal of Machine Learning Research},
    author = {Ernst, D and Geurts, P and Wehenkel, L},
    pages = {503–556}
}

@misc{farquhar2017a,
    title = {{TreeQN and ATreeC: Differentiable Tree Planning for Deep Reinforcement Learning}},
    author = {Farquhar, G and Rockt{\"{a}}schel, T and Igl, M and Whiteson, S},
    edition = {arXiv prep}
}

@inproceedings{li2011a,
    title = {{Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms}},
    booktitle = {Proceedings of the fourth ACM international conference on},
    author = {Li, L and Chu, W and Langford, J and Wang, X},
    pages = {297–306}
}

@misc{zhang2016a,
    title = {{Understanding deep learning requires rethinking generalization}},
    author = {Zhang, C and Bengio, S and Hardt, M and Recht, B and Vinyals, O},
    edition = {arXiv prep}
}

@misc{bellemare2016a,
    title = {{Unifying Count-Based Exploration and Intrinsic Motivation}},
    author = {Bellemare, M G and Srinivasan, S and Ostrovski, G and Schaul, T and Saxton, D and Munos, R},
    edition = {arXiv prep}
}

@misc{juliani2018a,
    title = {{Unity: A General Platform for Intelligent Agents}},
    author = {Juliani, A and Berges, V.-P. and Vckay, E and Gao, Y and Henry, H and Mattar, M and Lange, D},
    edition = {arXiv prep}
}

@inproceedings{schaul-a,
    title = {{Universal value function approximators}},
    booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
    pages = {1312–1320},
    volume = {15}
}

@incollection{finn2016a,
    title = {{Unsupervised learning for physical interaction through video prediction}},
    booktitle = {Advances In Neural Information Processing Systems},
    author = {Finn, C and Goodfellow, I and Levine, S},
    pages = {64–72}
}

@article{Roy2016,
    title = {{Using Word Embeddings for Automatic Query Expansion}},
    year = {2016},
    author = {Roy, Dwaipayan and Paul, Debjyoti and Mitra, Mandar and Garain, Utpal},
    month = {6},
    url = {http://arxiv.org/abs/1606.07608},
    arxivId = {1606.07608}
}

@incollection{tamar2016a,
    title = {{Value iteration networks}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Tamar, A and Levine, S and Abbeel, P and WU, Y and Thomas, G},
    pages = {2146–2154}
}

@misc{oh2017a,
    title = {{Value Prediction Network}},
    author = {Oh, J and Singh, S and Lee, H},
    edition = {arXiv prep}
}

@article{sunehag2017a,
    title = {{Value-Decomposition Networks For Cooperative Multi-Agent Learning}},
    journal = {Tuyls, et al},
    author = {Sunehag, P and Lever, G and Gruslys, A and Czarnecki, W M and Zambaldi, V and Jaderberg, M and Lanctot, M and Sonnerat, N and Leibo, J Z and {K.}},
    edition = {arXiv prep}
}

@article{munos2002a,
    title = {{Variable resolution discretization in optimal control}},
    journal = {Machine learning},
    author = {Munos, R and Moore, A},
    number = {2},
    pages = {291–323},
    volume = {49}
}

@misc{fonteneau2008a,
    title = {{Variable selection for dynamic treatment regimes: a reinforcement learning approach}},
    author = {Fonteneau, R and Wehenkel, L and Ernst, D}
}

@article{james2003a,
    title = {{Variance and bias for general loss functions}},
    journal = {Machine Learning},
    author = {James, G M},
    number = {2},
    pages = {115–135},
    volume = {51}
}

@misc{gregor2016a,
    title = {{Variational Intrinsic Control}},
    author = {Gregor, K and Rezende, D J and Wierstra, D},
    edition = {arXiv prep}
}

@misc{kalchbrenner2016a,
    title = {{Video pixel networks}},
    author = {Kalchbrenner, N and v. d. Oord, A and Simonyan, K and Danihelka, I and Vinyals, O and Graves, A and Kavukcuoglu, K},
    edition = {arXiv prep}
}

@incollection{houthooft2016a,
    title = {{Vime: Variational information maximizing exploration}},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Houthooft, R and Chen, X and Duan, Y and Schulman, J and Turck, F.De and Abbeel, P},
    pages = {1109–1117}
}

@misc{you2017a,
    title = {{Virtual to Real Reinforcement Learning for Autonomous Driving}},
    author = {You, Y and Pan, X and Wang, Z and Lu, C},
    edition = {arXiv prep}
}

@techreport{erhan2009a,
    title = {{Visualizing higher-layer features of a deep network}},
    author = {Erhan, D and Bengio, Y and Courville, A and Vincent, P},
    number = {3},
    pages = {1},
    volume = {1341},
    institution = {University of Montreal}
}

@incollection{kempka2016a,
    title = {{Vizdoom: A doom-based ai research platform for visual reinforcement learning}},
    booktitle = {Computational Intelligence and Games (CIG), 2016 IEEE Conference on. IEEE},
    author = {Kempka, M and Wydmuch, M and Runc, G and Toczek, J and Ja{\'{s}}kowski, W},
    pages = {1–8}
}

@misc{tessler2017a,
    title = {{“A Deep Hierarchical Approach to Lifelong Learning in Minecraft.” In: AAAI. 1553–1561}},
    author = {Tessler, C and Givony, S and Zahavy, T and Mankowitz, D J and Mannor, S}
}

@misc{konda2000a,
    title = {{“Actor-critic algorithms”. In: Advances in neural information processing systems. 1008–1014}},
    author = {Konda, V R and Tsitsiklis, J N}
}

@misc{ng2000a,
    title = {{“Algorithms for inverse reinforcement learning.” In: Icml}},
    author = {Ng, A Y and Russell, S J},
    pages = {663–670}
}

@incollection{ravindran2004a,
    title = {{“An algebraic approach to abstraction in reinforcement learning”. PhD thesis}},
    author = {Ravindran, B and Barto, A G},
    url = {at Amherst.}
}

@misc{henderson2017a,
    title = {{“Benchmark Environments for Multitask Learning in Continuous Domains”. ICML Lifelong Learning: A Reinforcement Learning Approach Workshop}},
    author = {Henderson, P and Chang, W.-D. and Shkurti, F and Hansen, J and Meger, D and Dudek, G}
}

@misc{petrik2009a,
    title = {{“Biasing approximate dynamic programming with a lower discount factor”. In: Advances in neural information processing systems. 1265–1272}},
    author = {Petrik, M and Scherrer, B}
}

@misc{lecun1995a,
    title = {{“Convolutional networks for images, speech, and time series”. The handbook of brain theory and neural networks}},
    author = {LeCun, Y and Bengio, Y},
    address = {3361(10}
}

@misc{hadfield-menell2016a,
    title = {{“Cooperative inverse reinforcement learning”. In: Advances in neural information processing systems. 3909–3917}},
    author = {Hadfield-Menell, D and Russell, S J and Abbeel, P and Dragan, A}
}

@misc{van2016a,
    title = {{“Deep Reinforcement Learning with Double Q-Learning.” In: AAAI. 2094–2100}},
    author = {Van Hasselt, H and Guez, A and Silver, D}
}

@misc{watter2015a,
    title = {{“Embed to control: A locally linear latent dynamics model for control from raw images”. In: Advances in neural information processing systems. 2746–2754}},
    author = {Watter, M and Springenberg, J and Boedecker, J and Riedmiller, M}
}

@book{rasmussen2004a,
    title = {{“Gaussian processes in machine learning”. In: Advanced lectures on machine learning}},
    author = {Rasmussen, C E},
    pages = {63–71},
    publisher = {Springer}
}

@misc{sutton1996a,
    title = {{“Generalization in reinforcement learning: Successful examples using sparse coarse coding”. Advances in neural information processing systems: 1038–1044}},
    author = {Sutton, R S}
}

@misc{goodfellow2014a,
    title = {{“Generative adversarial nets”. In: Advances in neural information processing systems. 2672– 2680}},
    author = {Goodfellow, I and Pouget-Abadie, J and Mirza, M and Xu, B and Warde-Farley, D and Ozair, S and Courville, A and Bengio, Y}
}

@misc{krizhevsky2012a,
    title = {{“Imagenet classification with deep convolutional neural networks”. In: Advances in neural information processing systems. 1097–1105}},
    author = {Krizhevsky, A and Sutskever, I and Hinton, G E}
}

@misc{watkins1989a,
    title = {{“Learning from delayed rewards”. PhD thesis}},
    author = {Watkins, C.J.C.H.},
    address = {King’s College, Cambridge}
}

@misc{kalakrishnan2013a,
    title = {{“Learning objective functions for manipulation”. In: Robotics and Automation (ICRA), 2013 IEEE International Conference on. IEEE. 1331–1336}},
    author = {Kalakrishnan, M and Pastor, P and Righetti, L and Schaal, S}
}

@misc{singh1994a,
    title = {{“Learning Without State-Estimation in Partially Observable Markovian Decision Processes.” In: ICML}},
    author = {Singh, S P and Jaakkola, T S and Jordan, M I},
    pages = {284–292}
}

@misc{silver2013a,
    title = {{“Lifelong Machine Learning Systems: Beyond Learning Algorithms.” In: AAAI Spring Symposium: Lifelong Machine Learning}},
    author = {Silver, D L and Yang, Q and Li, L},
    pages = {5},
    volume = {13}
}

@inproceedings{duchesne2017a,
    title = {{“Machine learning of real-time power systems reliability management response”. PowerTech Manchester 2017 Proceedings}},
    author = {Duchesne, L and Karangelos, E and Wehenkel, L}
}

@misc{todorov2012a,
    title = {{“MuJoCo: A physics engine for model-based control”. In: Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on. IEEE. 5026–5033}},
    author = {Todorov, E and Erez, T and Tassa, Y}
}

@misc{brys2014a,
    title = {{“Multi-objectivization of reinforcement learning problems by reward shaping”. In: Neural Networks (IJCNN), 2014 International Joint Conference on. IEEE. 2315–2322}},
    author = {Brys, T and Harutyunyan, A and Vrancx, P and Taylor, M E and Kudenko, D and Now{\'{e}}, A}
}

@book{fukushima1982a,
    title = {{“Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition”. In: Competition and cooperation in neural nets}},
    author = {Fukushima, K and Miyake, S},
    pages = {267–285},
    publisher = {Springer}
}

@misc{barto1983a,
    title = {{“Neuronlike adaptive elements that can solve difficult learning control problems”. IEEE transactions on systems, man, and cybernetics}},
    author = {Barto, A G and Sutton, R S and Anderson, C W},
    pages = {834–846}
}

@inproceedings{mandel2014a,
    title = {{“Offline policy evaluation across representations with applications to educational games”. In: Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems. International Foundation for Autonomous Agents and Multiagent Sys}},
    author = {Mandel, T and Liu, Y.-E. and Levine, S and Brunskill, E and Popovic, Z}
}

@misc{lample2017a,
    title = {{“Playing FPS Games with Deep Reinforcement Learning.” In: AAAI. 2140–2146}},
    author = {Lample, G and Chaplot, D S}
}

@misc{sutton2000a,
    title = {{“Policy gradient methods for reinforcement learning with function approximation”. In: Advances in neural information processing systems. 1057–1063}},
    author = {Sutton, R S and McAllester, D A and Singh, S P and Mansour, Y}
}

@article{whiteson2011a,
    title = {{“Protecting against evaluation overfitting in empirical reinforcement learning”. In: Adaptive Dynamic Programming And Reinforcement Learning (ADPRL), 2011 IEEE Symposium on}},
    journal = {IEEE},
    author = {Whiteson, S and Tanner, B and Taylor, M E and Stone, P},
    pages = {120–127}
}

@misc{boularias2011a,
    title = {{“Relative Entropy Inverse Reinforcement Learning.” In: AISTATS}},
    author = {Boularias, A and Kober, J and Peters, J},
    pages = {182–189}
}

@misc{baird1995a,
    title = {{“Residual algorithms: Reinforcement learning with function approximation”. In: ICML}},
    author = {Baird, L},
    pages = {30–37}
}

@misc{mcgovern1997a,
    title = {{“Roles of macroactions in accelerating reinforcement learning”. In: Grace Hopper celebration of women in computing}},
    author = {McGovern, A and Sutton, R S and Fagg, A H}
}

@book{ortner2014a,
    title = {{“Selecting nearoptimal approximate state representations in reinforcement learning”. In: International Conference on Algorithmic Learning Theory}},
    author = {Ortner, R and Maillard, O.-A. and Ryabko, D},
    pages = {140–154},
    publisher = {Springer}
}

@misc{gordon1996a,
    title = {{“Stable fitted reinforcement learning”. In: Advances in neural information processing systems. 1052–1058}},
    author = {Gordon, G J}
}

@misc{johnson2016a,
    title = {{“The Malmo Platform for Artificial Intelligence Experimentation.” In: IJCAI. 4246–4247}},
    author = {Johnson, M and Hofmann, K and Hutton, T and Bignell, D}
}

@misc{schulman2015a,
    title = {{“Trust Region Policy Optimization”. In: ICML. 1889–1897}},
    author = {Schulman, J and Levine, S and Abbeel, P and Jordan, M I and Moritz, P}
}

@misc{mohamed2015a,
    title = {{“Variational information maximisation for intrinsically motivated reinforcement learning”. In: Advances in neural information processing systems. 2125–2133}},
    author = {Mohamed, S and Rezende, D J}
}

@book{ueno2017a,
    title = {{““Re: ROS”: Prototyping of Reinforcement Learning Environment for Asynchronous Cognitive Architecture”. In: First International Early Research Career Enhancement School on Biologically Inspired Cognitive Architectures}},
    author = {Ueno, S and Osawa, M and Imai, M and Kato, T and Yamakawa, H},
    publisher = {Springer}
}

@techreport{Garcia2015ALearning,
    title = {{A Comprehensive Survey on Safe Reinforcement Learning}},
    year = {2015},
    booktitle = {Journal of Machine Learning Research},
    author = {Garc{\'{i}}a, Javier and Fern{\'{a}}ndez, Fernando},
    pages = {1437--1480},
    volume = {16},
    url = {http://jmlr.org/papers/volume16/garcia15a/garcia15a.pdf},
    keywords = {reinforcement learning, risk sensitivity, safe exploration, teacher advice}
}

@article{Ollerton2009AHypothesis,
    title = {{A global test of the pollination syndrome hypothesis}},
    year = {2009},
    journal = {Annals of Botany},
    author = {Ollerton, Jeff and Alarcon, Ruben and Waser, Nickolas M. and Price, Mary V. and Watts, Stella and Cranmer, Louise and Hingston, Andrew and Peter, Craig I. and Rotenberry, John},
    number = {9},
    pages = {1471--1480},
    volume = {103},
    url = {https://gluebenchmark.com/leaderboard http://arxiv.org/abs/1802.05365%0Ahttp://arxiv.org/abs/1705.00108%0Ahttp://arxiv.org/abs/1308.0850%0Ahttp://arxiv.org/abs/1810.04805%0Ahttp://arxiv.org/abs/1511.01432%0Ahttps://gluebenchmark.com/leaderboard},
    isbn = {0305-7364},
    doi = {10.1093/aob/mcp031},
    issn = {10958290},
    pmid = {19218577},
    arxivId = {1802.05365},
    keywords = {Convergent evolution, floral traits, global, montane meadow, multidimensional scaling, mutualism, phenotype space, pollination syndromes, temperate grassland, test, tropical forest, tropical mountains}
}

@article{Elith2011AEcologists,
    title = {{A statistical explanation of MaxEnt for ecologists}},
    year = {2011},
    journal = {Diversity and Distributions},
    author = {Elith, Jane and Phillips, Steven J. and Hastie, Trevor and Dud{\'{i}}k, Miroslav and Chee, Yung En and Yates, Colin J.},
    number = {1},
    month = {1},
    pages = {43--57},
    volume = {17},
    publisher = {Wiley/Blackwell (10.1111)},
    url = {http://doi.wiley.com/10.1111/j.1472-4642.2010.00725.x},
    doi = {10.1111/j.1472-4642.2010.00725.x},
    issn = {13669516},
    keywords = {Absence, ecological niche, entropy, machine learning, presence‐only, species distribution model}
}

@article{DivinoBayesianData,
    title = {{Bayesian logistic regression for presence-only data}},
    journal = {Stochastic Environmental Research and Risk Assessment},
    author = {Divino, Fabio and Golini, Natalia and Jona Lasinio, Giovanna and Penttinen, Antti},
    url = {https://link.springer.com/content/pdf/10.1007%2Fs00477-015-1064-y.pdf},
    doi = {10.1007/s00477-015-1064-y},
    keywords = {Case-control design, Censored data, Data augmentation, Markov Chain Monte Carlo algorithm, Stratified sampling, Two levels scheme}
}

@article{Li2018DeepLearning,
    title = {{Deep Reinforcement Learning}},
    year = {2018},
    author = {Li, Yuxi},
    month = {10},
    url = {http://arxiv.org/abs/1810.06339},
    arxivId = {1810.06339}
}

@techreport{Li2018DEEPOVERVIEW,
    title = {{DEEP REINFORCEMENT LEARNING: AN OVERVIEW}},
    year = {2018},
    author = {Li, Yuxi},
    url = {https://arxiv.org/abs/},
    arxivId = {1701.07274v6}
}

@article{Li2017DeepOverview,
    title = {{Deep Reinforcement Learning: An Overview}},
    year = {2017},
    author = {Li, Yuxi},
    month = {1},
    url = {http://arxiv.org/abs/1701.07274},
    arxivId = {1701.07274}
}

@techreport{Roy2005DRAFTPrograms,
    title = {{DRAFT Formulation and Analysis of Linear Programs}},
    year = {2005},
    author = {Roy, Benjamin Van and Mason, Kahn},
    url = {https://web.stanford.edu/~ashishg/msande111/notes/intro.pdf}
}

@article{VanRoy2006PerformanceAggregation,
    title = {{Performance Loss Bounds for Approximate Value Iteration with State Aggregation}},
    year = {2006},
    journal = {Mathematics of Operations Research},
    author = {Van Roy, Benjamin},
    number = {2},
    pages = {234},
    volume = {31},
    url = {http://pubsonline.informs.org244.https://doi.org/10.1287/moor.1060.0188http://www.informs.org},
    doi = {10.1287/moor.1060.0188}
}

@article{Mnih2013PlayingLearning,
    title = {{Playing Atari with Deep Reinforcement Learning}},
    year = {2013},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
    month = {12},
    url = {http://arxiv.org/abs/1312.5602},
    arxivId = {1312.5602}
}

@techreport{SuttonPolicyApproximation,
    title = {{Policy Gradient Methods for Reinforcement Learning with Function Approximation}},
    author = {Sutton, Richard S and Mcallester, David and Singh, Satinder and Mansour, Yishay},
    url = {https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf}
}

@article{AbdulhaiReinforcementControl,
    title = {{Reinforcement Learning for True Adaptive Traffic Signal Control}},
    author = {Abdulhai, Baher and Pringle, Rob and Karakoulas, Grigoris J},
    url = {http://www.dcsc.tudelft.nl/~sc4081/assign/pap/Reinforcement_Learning2.pdf},
    doi = {10.1061/ASCE0733-947X2003129:3278},
    keywords = {Adaptive systems, CE Database subject headings: Traffic signal controllers, Intelligent transportation systems, Traffic control, Traffic management}
}

@techreport{PetrikSafeRegret,
    title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
    author = {Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
    url = {http://marek.petrik.us/pub/Petrik2016b.pdf}
}

@techreport{DeFarias2003THEPROGRAMMING,
    title = {{THE LINEAR PROGRAMMING APPROACH TO APPROXIMATE DYNAMIC PROGRAMMING}},
    year = {2003},
    author = {De Farias, D P and Roy, B Van},
    url = {http://www.mit.edu/~pucci/discountedLP.pdf}
}

@article{Smith2006TheAnalysis,
    title = {{The Optimizer's Curse: Skepticism and Postdecision Surprise in Decision Analysis}},
    year = {2006},
    journal = {MANAGEMENT SCIENCE},
    author = {Smith, James E and Winkler, Robert L},
    number = {3},
    pages = {311--322},
    volume = {52},
    url = {https://faculty.fuqua.duke.edu/~jes9/bio/The_Optimizers_Curse.pdf},
    doi = {10.1287/mnsc.1050.0451},
    keywords = {Bayesian models, decision analysis, disappointment History: Accepted by David E Bell,, optimization, optimizer's curse, postdecision surprise}
}

@article{Schulman2015TrustOptimization,
    title = {{Trust Region Policy Optimization}},
    year = {2015},
    author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
    month = {2},
    url = {http://arxiv.org/abs/1502.05477},
    arxivId = {1502.05477}
}

@article{Iyengar2000WhenThing,
    title = {{When Choice is Demotivating: Can One Desire Too Much of a Good Thing?}},
    year = {2000},
    author = {Iyengar, Sheena S and Lepper, Mark R},
    url = {https://faculty.washington.edu/jdb/345/345%20Articles/Iyengar%20%26%20Lepper%20(2000).pdf},
    doi = {10.1037/0022-3514.79.6.995}
}